*** linux-sh4-2.6.23.17_stm23_0119-orig/drivers/stm/710x_fdma2.c	2009-06-06 20:17:15.000000000 +0200
--- linux-sh4/drivers/stm/710x_fdma2.c	2009-06-10 11:15:45.000000000 +0200
***************
*** 4,10 ****
   *          Stuart Menefy <stuart.menefy@st.com>
   *
   * May be copied or modified under the terms of the GNU General Public
!  * License. See linux/COPYING for more information.
   */
  
  #include <linux/interrupt.h>
--- 4,10 ----
   *          Stuart Menefy <stuart.menefy@st.com>
   *
   * May be copied or modified under the terms of the GNU General Public
!  * License.  See linux/COPYING for more information.
   */
  
  #include <linux/interrupt.h>
***************
*** 14,174 ****
  #include <linux/dmapool.h>
  #include <linux/stm/fdma-plat.h>
  #include <linux/stm/stm-dma.h>
- #include "fdma.h"
- 
  
  
! static int fdma_setup_freerunning_node(struct stm_dma_params *params,
! 		struct fdma_llu_entry *llu)
  {
  	memset(llu, 0, sizeof(*llu));
  
  	if (params->node_pause)
! 		llu->control |= SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
  
  	if (params->node_interrupt)
  		llu->control |= SET_NODE_COMP_IRQ;
  
! 	if (DIM_SRC(params->dim) == 0)
! 		llu->control |= NODE_ADDR_STATIC << SOURCE_ADDR;
! 	else
! 		llu->control |= NODE_ADDR_INCR << SOURCE_ADDR;
  
! 	if (DIM_DST(params->dim) == 0)
! 		llu->control |= NODE_ADDR_STATIC << DEST_ADDR;
! 	else
! 		llu->control |= NODE_ADDR_INCR << DEST_ADDR;
  
! 	llu->line_len = params->line_len;
! 	llu->sstride = params->sstride;
! 	llu->dstride = params->dstride;
  	return 0;
  }
  
! static int fdma_setup_paced_node(struct stm_dma_params *params,
! 		struct fdma_llu_entry *llu)
  
  {
  	memset(llu, 0, sizeof(*llu));
  
  	/* Moved this into the extrapolate functions so that we can
  	 * change channel in the same way as address. Yech */
! 	/* llu->control = params->req_line; */
! 	llu->size_bytes = params->node_bytes;
  	llu->line_len = params->node_bytes;
  
  	if (params->node_pause)
  		/* In order to recieve the pause interrupt
  		 * we must also enable end of node interrupts. */
! 		llu->control |= SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
  
  	if (params->node_interrupt)
  		llu->control |= SET_NODE_COMP_IRQ;
  
! 	if (DIM_SRC(params->dim) == 0)
! 		llu->control |= NODE_ADDR_STATIC << SOURCE_ADDR;
! 	else
! 		llu->control |= NODE_ADDR_INCR << SOURCE_ADDR;
  
! 	if (DIM_DST(params->dim) == 0)
! 		llu->control |= NODE_ADDR_STATIC << DEST_ADDR;
! 	else
! 		llu->control |= NODE_ADDR_INCR << DEST_ADDR;
  
  	return 0;
  }
  
! static struct fdma_llu_node *fdma_extrapolate_simple(
! 		struct stm_dma_params *params,
! 		struct fdma_xfer_descriptor *desc,
! 		struct fdma_llu_node *llu_node)
! {
! 	struct fdma_llu_entry *dest_llu = llu_node->virt_addr;
! 
! 	dest_llu->control = desc->template_llu.control |
! 			(params->req ? params->req->local_req_line : 0);
! 	dest_llu->size_bytes = params->node_bytes;
! 	dest_llu->saddr	 = params->sar;
! 	dest_llu->daddr	 = params->dar;
  	if (desc->extrapolate_line_len)
  		dest_llu->line_len = params->node_bytes;
  	else
  		dest_llu->line_len = desc->template_llu.line_len;
! 	dest_llu->sstride = desc->template_llu.sstride;
! 	dest_llu->dstride = desc->template_llu.dstride;
  
  	return llu_node;
  }
  
! static struct fdma_llu_node *fdma_extrapolate_sg_src(
! 		struct stm_dma_params *params,
! 		struct fdma_xfer_descriptor *desc,
! 		struct fdma_llu_node *llu_node)
  {
  	int i;
! 	struct scatterlist *sg = params->srcsg;
! 	struct fdma_llu_node *last_llu_node = llu_node;
  
! 	for (i = 0; i < params->sglen; i++) {
! 		struct fdma_llu_entry *dest_llu = llu_node->virt_addr;
  
! 		dest_llu->control = desc->template_llu.control;
! 		dest_llu->size_bytes = sg_dma_len(sg);
! 		dest_llu->saddr	= sg_dma_address(sg);
! 		dest_llu->daddr	= params->dar;
  		if (desc->extrapolate_line_len)
  			dest_llu->line_len = sg_dma_len(sg);
  		else
  			dest_llu->line_len = desc->template_llu.line_len;
! 		dest_llu->sstride = desc->template_llu.sstride;
! 		dest_llu->dstride = 0;
  
  		last_llu_node = llu_node++;
! 		dest_llu->next_item = llu_node->dma_addr;
  		sg++;
  	}
  
  	return last_llu_node;
  }
  
! static struct fdma_llu_node *fdma_extrapolate_sg_dst(
! 		struct stm_dma_params *params,
! 		struct fdma_xfer_descriptor *desc,
! 		struct fdma_llu_node *llu_node)
  {
  	int i;
! 	struct scatterlist *sg = params->dstsg;
! 	struct fdma_llu_node *last_llu_node = llu_node;
  
! 	for (i = 0; i < params->sglen; i++) {
! 		struct fdma_llu_entry *dest_llu = llu_node->virt_addr;
  
! 		dest_llu->control = desc->template_llu.control;
! 		dest_llu->size_bytes = sg_dma_len(sg);
! 		dest_llu->saddr	 = params->sar;
! 		dest_llu->daddr	 = sg_dma_address(sg);
  		if (desc->extrapolate_line_len)
  			dest_llu->line_len = sg_dma_len(sg);
  		else
  			dest_llu->line_len = desc->template_llu.line_len;
! 		dest_llu->sstride = 0;
! 		dest_llu->dstride = desc->template_llu.dstride;
  
  		last_llu_node = llu_node++;
! 		dest_llu->next_item = llu_node->dma_addr;
  		sg++;
  	}
  
  	return last_llu_node;
  }
  
! static int fdma_resize_nodelist_mem(struct fdma *fdma,
! 		struct fdma_xfer_descriptor *desc, unsigned int new_nnodes,
! 		gfp_t context)
  {
  	int old_list_size, new_list_size;
  	unsigned int cur_nnodes;
! 	struct fdma_llu_node *new_nodes;
  
  	/* This holds the number of allocated nodes, which may differ
  	 * from the old or new size. It must be maintained so that
--- 14,177 ----
  #include <linux/dmapool.h>
  #include <linux/stm/fdma-plat.h>
  #include <linux/stm/stm-dma.h>
  
+ #include "fdma.h"
  
! static int setup_freerunning_node(struct stm_dma_params *params,
! 				  struct fdma_llu_entry* llu)
  {
  	memset(llu, 0, sizeof(*llu));
  
  	if (params->node_pause)
! 		llu->control |=  SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
  
  	if (params->node_interrupt)
  		llu->control |= SET_NODE_COMP_IRQ;
  
! 	if (DIM_SRC(params->dim) == 0) {
! 		llu->control |= NODE_ADDR_STATIC <<SOURCE_ADDR;
! 	} else {
! 		llu->control |= NODE_ADDR_INCR <<SOURCE_ADDR;
! 	}
  
! 	if (DIM_DST(params->dim) == 0) {
! 		llu->control |= NODE_ADDR_STATIC <<DEST_ADDR;
! 	} else {
! 		llu->control |= NODE_ADDR_INCR <<DEST_ADDR;
! 	}
  
! 	llu->line_len		= params->line_len;
! 	llu->sstride 		= params->sstride;
! 	llu->dstride 		= params->dstride;
  	return 0;
  }
  
! static int setup_paced_node(struct stm_dma_params *params,
! 			    fdma_llu_entry* llu)
  
  {
  	memset(llu, 0, sizeof(*llu));
  
  	/* Moved this into the extrapolate functions so that we can
  	 * change channel in the same way as address. Yech */
! 	/* llu->control= params->req_line; */
! 	llu->size_bytes= params->node_bytes;
  	llu->line_len = params->node_bytes;
  
  	if (params->node_pause)
  		/* In order to recieve the pause interrupt
  		 * we must also enable end of node interrupts. */
! 		llu->control |=  SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
  
  	if (params->node_interrupt)
  		llu->control |= SET_NODE_COMP_IRQ;
  
! 	if (DIM_SRC(params->dim) == 0) {
! 		llu->control |= NODE_ADDR_STATIC <<SOURCE_ADDR;
! 	} else {
! 		llu->control |= NODE_ADDR_INCR <<SOURCE_ADDR;
! 	}
  
! 	if (DIM_DST(params->dim) == 0) {
! 		llu->control |= NODE_ADDR_STATIC <<DEST_ADDR;
! 	} else {
! 		llu->control |= NODE_ADDR_INCR <<DEST_ADDR;
! 	}
  
  	return 0;
  }
  
! static struct llu_node* extrapolate_simple(
! 	struct stm_dma_params *params,
! 	struct dma_xfer_descriptor *desc,
! 	struct llu_node* llu_node)
! {
! 	struct fdma_llu_entry* dest_llu = llu_node->virt_addr;
! 
! 	dest_llu->control	= desc->template_llu.control |
! 		(params->req ? params->req->local_req_line : 0);
! 	dest_llu->size_bytes	= params->node_bytes;
! 	dest_llu->saddr		= params->sar;
! 	dest_llu->daddr		= params->dar;
  	if (desc->extrapolate_line_len)
  		dest_llu->line_len = params->node_bytes;
  	else
  		dest_llu->line_len = desc->template_llu.line_len;
! 	dest_llu->sstride	= desc->template_llu.sstride;
! 	dest_llu->dstride	= desc->template_llu.dstride;
  
  	return llu_node;
  }
  
! static struct llu_node* extrapolate_sg_src(
! 	struct stm_dma_params *params,
! 	struct dma_xfer_descriptor *desc,
! 	struct llu_node* llu_node)
  {
  	int i;
! 	struct scatterlist * sg = params->srcsg;
! 	struct llu_node* last_llu_node = llu_node;
  
! 	for (i=0; i<params->sglen; i++) {
! 		struct fdma_llu_entry* dest_llu = llu_node->virt_addr;
  
! 		dest_llu->control	= desc->template_llu.control;
! 		dest_llu->size_bytes	= sg_dma_len(sg);
! 		dest_llu->saddr		= sg_dma_address(sg);
! 		dest_llu->daddr		= params->dar;
  		if (desc->extrapolate_line_len)
  			dest_llu->line_len = sg_dma_len(sg);
  		else
  			dest_llu->line_len = desc->template_llu.line_len;
! 		dest_llu->sstride	= desc->template_llu.sstride;
! 		dest_llu->dstride	= 0;
  
  		last_llu_node = llu_node++;
! 		dest_llu->next_item	= llu_node->dma_addr;
  		sg++;
  	}
  
  	return last_llu_node;
  }
  
! static struct llu_node* extrapolate_sg_dst(
! 	struct stm_dma_params *params,
! 	struct dma_xfer_descriptor *desc,
! 	struct llu_node* llu_node)
  {
  	int i;
! 	struct scatterlist * sg = params->dstsg;
! 	struct llu_node* last_llu_node = llu_node;
  
! 	for (i=0; i<params->sglen; i++) {
! 		struct fdma_llu_entry* dest_llu = llu_node->virt_addr;
  
! 		dest_llu->control	= desc->template_llu.control;
! 		dest_llu->size_bytes	= sg_dma_len(sg);
! 		dest_llu->saddr		= params->sar;
! 		dest_llu->daddr		= sg_dma_address(sg);
  		if (desc->extrapolate_line_len)
  			dest_llu->line_len = sg_dma_len(sg);
  		else
  			dest_llu->line_len = desc->template_llu.line_len;
! 		dest_llu->sstride	= 0;
! 		dest_llu->dstride	= desc->template_llu.dstride;
  
  		last_llu_node = llu_node++;
! 		dest_llu->next_item	= llu_node->dma_addr;
  		sg++;
  	}
  
  	return last_llu_node;
  }
  
! static int resize_nodelist_mem(struct fdma_dev * fd,
! 			       struct dma_xfer_descriptor *desc,
! 			       unsigned int new_nnodes, gfp_t context)
  {
  	int old_list_size, new_list_size;
  	unsigned int cur_nnodes;
! 	struct llu_node* new_nodes;
  
  	/* This holds the number of allocated nodes, which may differ
  	 * from the old or new size. It must be maintained so that
***************
*** 176,186 ****
  	cur_nnodes = desc->alloced_nodes;
  
  	/* The only resize down we need to support is freeing everything. */
! 	if (new_nnodes == 0)
  		goto free_list;
  
! 	old_list_size = sizeof(struct fdma_llu_node) * desc->alloced_nodes;
! 	new_list_size = sizeof(struct fdma_llu_node) * new_nnodes;
  	new_nodes = kmalloc(new_list_size, context);
  	if (new_nodes == NULL)
  		goto free_list;
--- 179,190 ----
  	cur_nnodes = desc->alloced_nodes;
  
  	/* The only resize down we need to support is freeing everything. */
! 	if (new_nnodes == 0) {
  		goto free_list;
+ 	}
  
! 	old_list_size = sizeof(struct llu_node)*desc->alloced_nodes;
! 	new_list_size = sizeof(struct llu_node)*new_nnodes;
  	new_nodes = kmalloc(new_list_size, context);
  	if (new_nodes == NULL)
  		goto free_list;
***************
*** 192,201 ****
  
  	desc->llu_nodes = new_nodes;
  
! 	for (new_nodes += desc->alloced_nodes; cur_nnodes < new_nnodes;
! 			cur_nnodes++, new_nodes++) {
! 		new_nodes->virt_addr = dma_pool_alloc(fdma->llu_pool,
! 				context, &new_nodes->dma_addr);
  		if (new_nodes->virt_addr == NULL)
  			goto free_list;
  	}
--- 196,208 ----
  
  	desc->llu_nodes = new_nodes;
  
! 	for (new_nodes += desc->alloced_nodes;
! 	     cur_nnodes < new_nnodes;
! 	     cur_nnodes++, new_nodes++) {
! 		new_nodes->virt_addr = dma_pool_alloc(
! 					fd->llu_pool,
! 					context,
! 					&new_nodes->dma_addr);
  		if (new_nodes->virt_addr == NULL)
  			goto free_list;
  	}
***************
*** 204,213 ****
  	return 0;
  
  free_list:
! 	for (new_nodes = desc->llu_nodes; cur_nnodes;
! 			cur_nnodes--, new_nodes++)
! 		dma_pool_free(fdma->llu_pool, new_nodes->virt_addr,
! 				new_nodes->dma_addr);
  	if (desc->llu_nodes)
  		kfree(desc->llu_nodes);
  
--- 211,222 ----
  	return 0;
  
  free_list:
! 	new_nodes = desc->llu_nodes;
! 	for( ; cur_nnodes; cur_nnodes--, new_nodes++) {
! 		dma_pool_free(fd->llu_pool,
! 			      new_nodes->virt_addr,
! 			      new_nodes->dma_addr);
! 	}
  	if (desc->llu_nodes)
  		kfree(desc->llu_nodes);
  
***************
*** 217,304 ****
  	return -ENOMEM;
  }
  
! static void fdma_start_channel(struct fdma_channel *channel,
! 		unsigned long start_addr, unsigned long initial_count)
  {
- 	struct fdma *fdma = channel->fdma;
  	u32 cmd_sta_value = (start_addr | CMDSTAT_FDMA_START_CHANNEL);
  
! 	/* See comment in fdma_get_residue() for why we do this. */
! 	writel(initial_count, fdma->io_base + (channel->chan_num *
! 			NODE_DATA_OFFSET) + fdma->regs.fdma_cntn);
! 
! 	writel(cmd_sta_value, CMD_STAT_REG(channel->chan_num));
! 	writel(MBOX_CMD_START_CHANNEL << (channel->chan_num * 2),
! 			fdma->io_base + fdma->regs.fdma_cmd_set);
  }
  
! static int fdma_get_engine_status(struct fdma_channel *channel)
  {
! 	struct fdma *fdma = channel->fdma;
! 
! 	return readl(CMD_STAT_REG(channel->chan_num)) & 3;
  }
  
! static inline void fdma_handle_fdma_err_irq(struct fdma_channel *channel)
  {
! 	struct fdma *fdma = channel->fdma;
! 	void (*err_cb)(unsigned long) = channel->params->err_cb;
! 	unsigned long err_cb_parm = channel->params->err_cb_parm;
! 
! 	spin_lock(&fdma->channels_lock);
! 
! 	/* err is bits 2-4 */
! 	fdma_dbg(fdma, "%s: FDMA error %d on channel %d\n", __FUNCTION__,
! 			(readl(CMD_STAT_REG(chan_num)) >> 2) & 0x7, chan_num);
  
! 	/* According to the spec, in case of error transfer "may be
! 	 * aborted" (or may not be, sigh) so let's make the situation
! 	 * clear and stop it explicitly now. */
! 	writel(MBOX_CMD_PAUSE_CHANNEL << (channel->chan_num * 2),
! 			fdma->io_base + fdma->regs.fdma_cmd_set);
! 	channel->sw_state = FDMA_STOPPING;
  
! 	spin_unlock(&fdma->channels_lock);
  
! 	wake_up(&channel->dma_chan->wait_queue);
  
  	if (err_cb) {
! 		if (channel->params->err_cb_isr)
  			err_cb(err_cb_parm);
  		else
! 			tasklet_schedule(&channel->fdma_error);
  	}
  }
  
! static inline void fdma_handle_fdma_completion_irq(struct fdma_channel *channel)
  {
! 	struct fdma *fdma = channel->fdma;
! 	void (*comp_cb)(unsigned long) = channel->params->comp_cb;
! 	unsigned long comp_cb_parm = channel->params->comp_cb_parm;
  
! 	spin_lock(&fdma->channels_lock);
  
! 	switch (fdma_get_engine_status(channel)) {
  	case FDMA_CHANNEL_PAUSED:
! 		switch (channel->sw_state) {
  		case FDMA_RUNNING:	/* Hit a pause node */
  		case FDMA_PAUSING:
! 			channel->sw_state = FDMA_PAUSED;
  			break;
  		case FDMA_STOPPING:
! 			writel(0, CMD_STAT_REG(channel->chan_num));
! 			channel->sw_state = FDMA_IDLE;
  			break;
  		default:
  			BUG();
  		}
  		break;
  	case FDMA_CHANNEL_IDLE:
! 		switch (channel->sw_state) {
  		case FDMA_RUNNING:
  		case FDMA_PAUSING:
  		case FDMA_STOPPING:
! 			channel->sw_state = FDMA_IDLE;
  			break;
  		default:
  			BUG();
--- 226,307 ----
  	return -ENOMEM;
  }
  
! static void fdma_start_channel(struct fdma_dev * fd,
! 			      int ch_num,
! 			      unsigned long start_addr)
  {
  	u32 cmd_sta_value = (start_addr | CMDSTAT_FDMA_START_CHANNEL);
  
! 	writel(cmd_sta_value,CMD_STAT_REG(ch_num));
! 	writel(MBOX_STR_CMD(ch_num),fd->io_base +fd->regs.fdma_cmd_set);
  }
  
! static int stb710x_get_engine_status(struct fdma_dev * fd,int channel)
  {
! 	return readl(CMD_STAT_REG(channel))&3;
  }
  
! static inline void __handle_fdma_err_irq(struct fdma_dev * fd,int chan_num)
  {
! 	struct channel_status *chan = &fd->channel[chan_num];
! 	void (*err_cb)(unsigned long) = chan->params->err_cb;
! 	unsigned long err_cb_parm = chan->params->err_cb_parm;
  
! 	spin_lock(&fd->channel_lock);
  
! 	printk("%s ERROR CH_%d err %d\n",
! 		__FUNCTION__,
! 		chan_num,
! 		(int)( readl(CMD_STAT_REG(chan_num))& 0x1c) >>2);
! 			/*err is bits 2-4*/
! 	/*clearing the channel interface here will stop further
! 	 * transactions after the err and reset the channel*/
! 	writel(0,CMD_STAT_REG(chan_num));
! 	writel(readl(fd->io_base + fd->regs.fdma_cmd_sta),
! 	       fd->io_base + fd->regs.fdma_cmd_clr);
! 	chan->sw_state = FDMA_IDLE;
  
! 	spin_unlock(&fd->channel_lock);
  
+ //printk("%s: wake_up %x\n", __FUNCTION__, &chan->cur_cfg->wait_queue);
+ 	wake_up(&chan->cur_cfg->wait_queue);
  	if (err_cb) {
! 		if (chan->params->err_cb_isr)
  			err_cb(err_cb_parm);
  		else
! 			tasklet_schedule(&chan->fdma_error);
  	}
  }
  
! static inline void __handle_fdma_completion_irq(struct fdma_dev *fd,int chan_num)
  {
! 	struct channel_status *chan = &fd->channel[chan_num];
! 	void (*comp_cb)(unsigned long) = chan->params->comp_cb;
! 	unsigned long comp_cb_parm = chan->params->comp_cb_parm;
  
! 	spin_lock(&fd->channel_lock);
  
! 	switch(stb710x_get_engine_status(fd,chan_num)){
  	case FDMA_CHANNEL_PAUSED:
! 		switch (chan->sw_state) {
  		case FDMA_RUNNING:	/* Hit a pause node */
  		case FDMA_PAUSING:
! 			chan->sw_state = FDMA_PAUSED;
  			break;
  		case FDMA_STOPPING:
! 			writel(0, CMD_STAT_REG(chan_num));
! 			chan->sw_state = FDMA_IDLE;
  			break;
  		default:
  			BUG();
  		}
  		break;
  	case FDMA_CHANNEL_IDLE:
! 		switch (chan->sw_state) {
  		case FDMA_RUNNING:
  		case FDMA_PAUSING:
  		case FDMA_STOPPING:
! 			chan->sw_state = FDMA_IDLE;
  			break;
  		default:
  			BUG();
***************
*** 307,366 ****
  	case FDMA_CHANNEL_RUNNING:
  		break;
  	default:
! 		fdma_dbg(fdma, "ERR::FDMA2 unknown interrupt status \n");
  	}
  
! 	spin_unlock(&fdma->channels_lock);
! 
! 	wake_up(&channel->dma_chan->wait_queue);
  
  	if (comp_cb) {
! 		if (channel->params->comp_cb_isr)
  			comp_cb(comp_cb_parm);
  		else
! 			tasklet_schedule(&channel->fdma_complete);
  	}
  }
  
  static irqreturn_t fdma_irq(int irq, void *dev_id)
  {
! 	struct fdma *fdma = dev_id;
  	int chan_num;
! 	u32 status = readl(fdma->io_base + fdma->regs.fdma_int_sta);
! 	u32 masked = status & fdma->ch_status_mask;
  
! 	writel(masked, fdma->io_base + fdma->regs.fdma_int_clr);
! 	for (masked >>= fdma->ch_min * 2, chan_num = fdma->ch_min;
! 			masked != 0; masked >>= 2, chan_num++) {
! 		struct fdma_channel *channel = &fdma->channels[chan_num];
! 		/* error interrupts will raise boths bits, so check
! 		 * the err bit first */
! 		if (unlikely(masked & 2))
! 			fdma_handle_fdma_err_irq(channel);
! 		else if (masked & 1)
! 			fdma_handle_fdma_completion_irq(channel);
! 	}
! 
! 	/* Here we check to see if there is still pending ints for the other
! 	 * dmac, if so rely on it to signal IRQ_HANDLED once all vectors are
! 	 * cleared, we return IRQ_NONE. Otherwise we have handled everything
! 	 * so we can now safely returnd IRQ_HANDLED to lower the IRQ. */
! 	return IRQ_RETVAL(!(status & (~fdma->ch_status_mask)));
  }
  
  /* Paced channel handling */
  
  #ifdef CONFIG_CPU_SUBTYPE_STB7100
  
! static struct stm_dma_req fdma_reqs[FDMA_7100_REQ_LINES];
  
  /* This is the dummy xbar for 710x devices */
! static int xbar_local_req(int req_line, struct fdma_channel *channel)
  {
  	return req_line;
  }
  
! static void xbar_local_free(struct fdma_channel *channel, int local_req_line)
  {
  }
  
--- 310,369 ----
  	case FDMA_CHANNEL_RUNNING:
  		break;
  	default:
! 		fdma_dbg(fd, "ERR::FDMA2 unknown interrupt status \n");
  	}
  
! 	spin_unlock(&fd->channel_lock);
  
+ 	wake_up(&chan->cur_cfg->wait_queue);
  	if (comp_cb) {
! 		if (chan->params->comp_cb_isr)
  			comp_cb(comp_cb_parm);
  		else
! 			tasklet_schedule(&chan->fdma_complete);
  	}
  }
  
  static irqreturn_t fdma_irq(int irq, void *dev_id)
  {
! 	struct fdma_dev * fd = (struct fdma_dev *)dev_id;
  	int chan_num;
! 	u32 int_stat_val = readl(fd->io_base + fd->regs.fdma_int_sta);
! 	u32 cur_val = int_stat_val & fd->ch_status_mask;
  
! 	writel(cur_val, fd->io_base +fd->regs.fdma_int_clr);
! 	for (cur_val >>= fd->ch_min * 2, chan_num=fd->ch_min;
! 	     cur_val != 0;
! 	     cur_val >>= 2, chan_num++) {
! 		/*error interrupts will raise boths bits, so check
! 		 * the err bit first*/
! 		if(unlikely(cur_val & 2))
! 			__handle_fdma_err_irq(fd,chan_num);
! 		else if (cur_val & 1)
! 			__handle_fdma_completion_irq(fd, chan_num);
! 	}
! 
! 	/*here we check to see if there is still pending ints for the other dmac, if so
! 	 * rely on it to signal IRQ_HANDLED once all vectors are cleared, we return IRQ_NONE.
! 	 * otherwise we have handled everything so we can now safely returnd IRQ_HANDLED
! 	 * to lower the IRQ.*/
! 	return IRQ_RETVAL( !(cur_val & (~fd->ch_status_mask)) );
  }
  
  /* Paced channel handling */
  
  #ifdef CONFIG_CPU_SUBTYPE_STB7100
  
! static struct stm_dma_req fdma_reqs[STB7100_REQ_LINES];
  
  /* This is the dummy xbar for 710x devices */
! static int xbar_local_req(int req_line,
! 			  struct channel_status *chan)
  {
  	return req_line;
  }
  
! static void xbar_local_free(struct channel_status *chan, int local_req_line)
  {
  }
  
***************
*** 374,414 ****
  
  /* Real xbar device */
  
! static struct stm_dma_req fdma_reqs[FDMA_7200_REQ_LINES];
  
  struct xbar_dev {
  	struct resource *phys_mem;
! 	void *io_base;
  };
  
  /* Gross hack, we use a global static so the FDMA code can find the
   * xbar. */
! static struct xbar_dev *xbar_dev;
  
  /* Needs to be called with both the channel and xbar locks taken. */
! static int xbar_local_req(int req_line, struct fdma_channel *channel)
  {
! 	struct fdma *fdma = channel->fdma;
  	int local_req_line;
! 	void *xbar_addr;
  
! 	if (fdma->req_lines_inuse == ~0UL)
  		return -1;
  
! 	local_req_line = ffz(fdma->req_lines_inuse);
! 	fdma->req_lines_inuse |= 1 << local_req_line;
  
! 	xbar_addr = xbar_dev->io_base + (fdma->fdma_num * 0x80) +
! 			(local_req_line * 4);
  	writel(req_line, xbar_addr);
  
  	return local_req_line;
  }
  
! static void xbar_local_free(struct fdma_channel *channel, int local_req_line)
  {
! 	struct fdma *fdma = channel->fdma;
! 	fdma->req_lines_inuse &= ~(1 << local_req_line);
  }
  
  static int __init xbar_driver_probe(struct platform_device *pdev)
--- 377,419 ----
  
  /* Real xbar device */
  
! static struct stm_dma_req fdma_reqs[STB7200_REQ_LINES];
  
  struct xbar_dev {
  	struct resource *phys_mem;
! 	void* io_base;
  };
  
  /* Gross hack, we use a global static so the FDMA code can find the
   * xbar. */
! static struct xbar_dev* xbar_dev;
  
  /* Needs to be called with both the channel and xbar locks taken. */
! static int xbar_local_req(int req_line,
! 			  struct channel_status *chan)
  {
! 	struct fdma_dev *fd = chan->fd;
  	int local_req_line;
! 	void* xbar_addr;
  
! 	if (fd->req_lines_inuse == ~0UL)
  		return -1;
  
! 	local_req_line = ffz(fd->req_lines_inuse);
! 	fd->req_lines_inuse |= 1<<local_req_line;
  
! 	xbar_addr = xbar_dev->io_base +
! 		(fd->fdma_num * 0x80) +
! 		(local_req_line * 4);
  	writel(req_line, xbar_addr);
  
  	return local_req_line;
  }
  
! static void xbar_local_free(struct channel_status *chan, int local_req_line)
  {
! 	struct fdma_dev *fd = chan->fd;
! 	fd->req_lines_inuse &= ~(1<<local_req_line);
  }
  
  static int __init xbar_driver_probe(struct platform_device *pdev)
***************
*** 422,435 ****
  		return -ENOMEM;
  	}
  
! 	mem_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
! 	phys_base = mem_res->start;
! 	phys_size = mem_res->end - mem_res->start + 1;
  
! 	xd->phys_mem = request_mem_region(phys_base, phys_size, "xbar");
  	if (xd->phys_mem == NULL) {
  		kfree(xd);
! 		return -EBUSY;
  	}
  
  	xd->io_base = ioremap_nocache(phys_base, phys_size);
--- 427,440 ----
  		return -ENOMEM;
  	}
  
! 	mem_res = platform_get_resource(pdev,IORESOURCE_MEM,0);
!         phys_base = mem_res->start;
!         phys_size = mem_res->end - mem_res->start + 1;
  
!         xd->phys_mem = request_mem_region(phys_base, phys_size, "xbar");
  	if (xd->phys_mem == NULL) {
  		kfree(xd);
!                 return -EBUSY;
  	}
  
  	xd->io_base = ioremap_nocache(phys_base, phys_size);
***************
*** 441,447 ****
  	platform_set_drvdata(pdev, xd);
  	xbar_dev = xd;
  
! 	return 0;
  }
  
  static int xbar_driver_remove(struct platform_device *pdev)
--- 446,452 ----
  	platform_set_drvdata(pdev, xd);
  	xbar_dev = xd;
  
!        	return 0;
  }
  
  static int xbar_driver_remove(struct platform_device *pdev)
***************
*** 450,456 ****
  }
  
  static struct platform_driver xbar_driver = {
! 	.driver.name = "fdma-xbar",
  	.probe = xbar_driver_probe,
  	.remove = xbar_driver_remove,
  };
--- 455,463 ----
  }
  
  static struct platform_driver xbar_driver = {
! 	.driver = {
! 		.name = "fdma-xbar",
! 	},
  	.probe = xbar_driver_probe,
  	.remove = xbar_driver_remove,
  };
***************
*** 472,498 ****
  
  static DEFINE_SPINLOCK(fdma_req_lock);
  
! static struct stm_dma_req *fdma_req_allocate(unsigned int req_line,
! 		struct fdma_channel *channel)
  {
! 	struct stm_dma_req *req = NULL;
  	int local_req_line;
  
  	if ((req_line < 0) || (req_line >= ARRAY_SIZE(fdma_reqs)))
  		return NULL;
  
  	spin_lock(&fdma_req_lock);
! 	if (fdma_reqs[req_line].channel != NULL)
  		goto out;
  
  	req = &fdma_reqs[req_line];
  
! 	local_req_line = xbar_local_req(req_line, channel);
  	if (local_req_line == -1) {
  		goto out;
  	}
  
! 	req->channel = channel;
  	req->local_req_line = local_req_line;
  out:
  	spin_unlock(&fdma_req_lock);
--- 479,505 ----
  
  static DEFINE_SPINLOCK(fdma_req_lock);
  
! static struct stm_dma_req *fdma_req_allocate(unsigned int req_line, struct channel_status *chan)
  {
! 	struct stm_dma_req* req = NULL;
  	int local_req_line;
  
  	if ((req_line < 0) || (req_line >= ARRAY_SIZE(fdma_reqs)))
  		return NULL;
  
  	spin_lock(&fdma_req_lock);
! 	if (fdma_reqs[req_line].chan != NULL) {
  		goto out;
+ 	}
  
  	req = &fdma_reqs[req_line];
  
! 	local_req_line = xbar_local_req(req_line, chan);
  	if (local_req_line == -1) {
  		goto out;
  	}
  
! 	req->chan = chan;
  	req->local_req_line = local_req_line;
  out:
  	spin_unlock(&fdma_req_lock);
***************
*** 503,512 ****
  {
  	spin_lock(&fdma_req_lock);
  
! 	if (req->channel)
! 		xbar_local_free(req->channel, req->local_req_line);
  
! 	req->channel = NULL;
  
  	spin_unlock(&fdma_req_lock);
  }
--- 510,519 ----
  {
  	spin_lock(&fdma_req_lock);
  
! 	if (req->chan)
! 		xbar_local_free(req->chan, req->local_req_line);
  
! 	req->chan = NULL;
  
  	spin_unlock(&fdma_req_lock);
  }
***************
*** 517,648 ****
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! static void fdma_initialise(struct fdma *fdma)
  {
! /* These pokes come from the current STAPI tree.
   * The three magic vals are pokes to undocumented regs so
   * we don't know what they mean.
   *
   * The effect is to turn on and initialise the clocks
!  * and set all channels off */
  
! 	/* clear the status regs MBOX & IRQ */
! 	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_int_clr);
! 	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_cmd_clr);
  
  	/* Enable the FDMA block */
! 	writel(1, fdma->io_base + fdma->regs.fdma_sync_reg);
! 	writel(5, fdma->io_base + fdma->regs.fdma_clk_gate);
! 	writel(0, fdma->io_base + fdma->regs.fdma_clk_gate);
  
  }
! /* this function enables messaging and intr generation for all channels &
!  * starts the fdma running */
! static int fdma_enable_all_channels(struct fdma *fdma)
  {
! 	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_int_mask);
! 	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_cmd_mask);
! 	writel(1, fdma->io_base + fdma->regs.fdma_en);
! 	return readl(fdma->io_base + fdma->regs.fdma_en) & 1;
  }
! static int fdma_disable_all_channels(struct fdma *fdma)
  {
! 	writel(0, fdma->io_base + fdma->regs.fdma_int_mask);
! 	writel(0, fdma->io_base + fdma->regs.fdma_cmd_mask);
! 	writel(0, fdma->io_base + fdma->regs.fdma_en);
! 	return readl(fdma->io_base + fdma->regs.fdma_en) & ~1;
  }
  
! static void fdma_reset_channels(struct fdma *fdma)
  {
! 	int chan_num;
! 
! 	for (chan_num = fdma->ch_min; chan_num <= fdma->ch_max; chan_num++)
! 		writel(0, CMD_STAT_REG(chan_num));
  }
  
! static struct stm_dma_req *fdma_configure_pace_channel(
! 		struct fdma_channel *channel,
! 		struct stm_dma_req_config *req_config)
  {
! 	struct fdma *fdma = channel->fdma;
! 	void __iomem *req_base_reg = fdma->io_base + fdma->regs.fdma_req_ctln;
! 	struct stm_dma_req *req;
! 
! 	req = fdma_req_allocate(req_config->req_line, channel);
  
! 	if (req) {
! 		u32 req_ctl = 0;
! 
! 		req_ctl |= (req_config->hold_off & 0x0f) <<  0; /* Bits 3..0 */
! 		req_ctl |= (req_config->opcode & 0x0f) <<  4; /* 7..4 */
! 		req_ctl |= (req_config->rw & 0x01) << 14; /* 14 */
! 		req_ctl |= (req_config->initiator & 0x03) << 22; /* 23..22 */
! 		req_ctl |= ((req_config->count - 1) & 0x1f) << 24; /* 28..24 */
! 		req_ctl |= (req_config->increment & 0x01) << 29; /* 29 */
! 
! 		writel(req_ctl, req_base_reg +
! 				(req->local_req_line * CMD_STAT_OFFSET));
  	}
  
! 	return req;
! }
! 
! static int fdma_register_caps(struct fdma *fdma)
! {
! 	int chan_num, dma_chan_num;
! 	int err;
! 	int num_caps = fdma->ch_max - fdma->ch_min + 1;
! 	struct dma_chan_caps dmac_caps[num_caps];
! 	static const char *hb_caps[] = {STM_DMA_CAP_HIGH_BW, NULL};
! 	static const char *lb_caps[] = {STM_DMA_CAP_LOW_BW, NULL};
! 	static const char *eth_caps[] = {STM_DMA_CAP_ETH_BUF, NULL};
! 
! 	for (chan_num = fdma->ch_min, dma_chan_num = 0;
! 			chan_num <= fdma->ch_max;
! 			chan_num++, dma_chan_num++) {
! 		dmac_caps[dma_chan_num].ch_num = dma_chan_num;
! 		switch (chan_num) {
  		case 0 ... 3:
! 			dmac_caps[dma_chan_num].caplist = hb_caps;
  			break;
  		case 11:
! 			dmac_caps[dma_chan_num].caplist = eth_caps;
  			break;
  		default:
! 			dmac_caps[dma_chan_num].caplist = lb_caps;
  			break;
  		}
  	}
  
! 	err = register_chan_caps(fdma->name, dmac_caps);
! 	if (err != 0) {
! 		fdma_dbg(fdma, "%s %s failed to register capabilities err-%d\n",
! 				__FUNCTION__, fdma->name, err);
  		return -ENODEV;
  	}
! 
! 	return 0;
  }
  
! static int fdma_run_initialise_sequence(struct fdma *fdma)
  {
! 	fdma->llu_pool = dma_pool_create(fdma->name, NULL,
! 			sizeof(struct fdma_llu_entry), 32, 0);
! 
! 	if (fdma->llu_pool == NULL) {
! 		fdma_dbg(fdma, "%s Can't allocate dma_pool memory",
! 				__FUNCTION__);
  		return -ENOMEM;
  	}
  
! 	fdma_initialise(fdma);
! 	fdma_reset_channels(fdma);
! 
! 	if (!fdma_enable_all_channels(fdma))
  		return -ENODEV;
! 
! 	return 0;
  }
  
  /*---------------------------------------------------------------------*
--- 524,647 ----
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! static void fdma_initialise(struct fdma_dev * fd)
  {
! /*These pokes come from the current STAPI tree.
   * The three magic vals are pokes to undocumented regs so
   * we don't know what they mean.
   *
   * The effect is to turn on and initialise the clocks
!  * and set all channels off*/
  
! 	/*clear the status regs MBOX & IRQ*/
! 	writel(CLEAR_WORD, fd->io_base+fd->regs.fdma_int_clr);
! 	writel(CLEAR_WORD, fd->io_base+fd->regs.fdma_cmd_clr);
  
  	/* Enable the FDMA block */
! 	writel(1,fd->io_base+fd->regs.fdma_sync_reg);
! 	writel(5,fd->io_base+fd->regs.fdma_clk_gate);
! 	writel(0,fd->io_base+fd->regs.fdma_clk_gate);
  
  }
! /*this function enables messaging and intr generation for all channels &
!  * starts the fdma running*/
! static int fdma_enable_all_channels(struct fdma_dev * fd)
  {
! 	writel(CLEAR_WORD,fd->io_base + fd->regs.fdma_int_mask);
! 	writel(CLEAR_WORD,fd->io_base + fd->regs.fdma_cmd_mask);
! 	writel(1,fd->io_base +fd->regs.fdma_en);
! 	return (readl(fd->io_base + fd->regs.fdma_en) &1);
  }
! static int fdma_disable_all_channels(struct fdma_dev * fd)
  {
! 	writel(0x00,fd->io_base + fd->regs.fdma_int_mask);
! 	writel(0x00,fd->io_base + fd->regs.fdma_cmd_mask);
! 	writel(0,fd->io_base + fd->regs.fdma_en);
! 	return (readl(fd->io_base + fd->regs.fdma_en) &~1);
  }
  
! static void fdma_reset_channels(struct fdma_dev * fd)
  {
! 	int channel=0;
! 	for(;channel <(fd->ch_max-1);channel++)
! 		writel(0,CMD_STAT_REG(channel));
  }
  
! static struct stm_dma_req *stb710x_configure_pace_channel(struct fdma_dev *fd,
! 	struct dma_channel *channel,
! 	struct stm_dma_req_config *req_config)
  {
! 	struct channel_status *chan = FDMA_CHAN(channel);
! 	void __iomem *req_base_reg = fd->io_base+fd->regs.fdma_req_ctln;
! 	struct stm_dma_req *fdma_req;
! 	u32 req_ctl;
  
! 	fdma_req = fdma_req_allocate(req_config->req_line, chan);
! 	if (fdma_req == NULL) {
! 		return NULL;
  	}
  
! 	req_ctl = 0;
! 	req_ctl |= (req_config->hold_off	& 0x0f) <<  0;/*Bits 3.0*/
! 	req_ctl |= (req_config->opcode		& 0x0f) <<  4;/*7..4*/
! 	req_ctl |= (req_config->rw		& 0x01) << 14;/*14*/
! 	req_ctl |= (req_config->initiator	& 0x03) << 22;/*23..22*/
! 	req_ctl |= ((req_config->count-1)	& 0x1F) << 24;/*28..24*/
! 	req_ctl |= (req_config->increment	& 0x01) << 29;/*29*/
! 
! 	writel(req_ctl, req_base_reg + (fdma_req->local_req_line * CMD_STAT_OFFSET));
! 
! 	return fdma_req;
! }
! 
! static int fdma_register_caps(struct fdma_dev * fd)
! {
! 	int channel = fd->ch_min;
! 	int res=0;
! 	int num_caps = fd->ch_max - fd->ch_min + 1;
! 	struct dma_chan_caps  dmac_caps[num_caps];
! 	static const char* hb_caps[] = {STM_DMA_CAP_HIGH_BW,NULL};
! 	static const char* lb_caps[] = {STM_DMA_CAP_LOW_BW,NULL};
! 	static const char* eth_caps[] = {STM_DMA_CAP_ETH_BUF,NULL};
! 
! 	for (;channel <= fd->ch_max;channel++) {
! 		dmac_caps[channel-fd->ch_min].ch_num = channel;
! 		switch (channel) {
  		case 0 ... 3:
! 			dmac_caps[channel-fd->ch_min].caplist = hb_caps;
  			break;
  		case 11:
! 			dmac_caps[channel-fd->ch_min].caplist = eth_caps;
  			break;
  		default:
! 			dmac_caps[channel-fd->ch_min].caplist = lb_caps;
  			break;
  		}
  	}
+ 	res= register_chan_caps(fd->name, &dmac_caps[0]);
  
! 	if(res!=0){
! 		fdma_dbg(fd, "%s %s failed to register capabilities err-%d\n",
! 			__FUNCTION__, fd->name, res);
  		return -ENODEV;
  	}
! 	else return 0;
  }
  
! static int fdma_run_initialise_sequence(struct fdma_dev *fd)
  {
! 	fd->llu_pool = dma_pool_create(fd->name, NULL,
! 					sizeof(struct fdma_llu_entry),32,0);
! 	if (fd->llu_pool == NULL) {
! 		fdma_dbg(fd, "%s Can't allocate dma_pool memory",__FUNCTION__);
  		return -ENOMEM;
  	}
+ 	fdma_initialise(fd);
+ 	fdma_reset_channels(fd);
  
! 	if(!fdma_enable_all_channels(fd))
  		return -ENODEV;
! 	else return  0;
  }
  
  /*---------------------------------------------------------------------*
***************
*** 651,707 ****
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! static void fdma_get_fw_revision(struct fdma *fdma,
! 		int *major, int *minor)
  {
! 	int reg = readl(fdma->io_base + fdma->regs.fdma_dmem_region);
! 
! 	*major = (reg & 0xff0000) >> 16;
! 	*minor = (reg & 0xff00) >> 8;
  }
  
! static void fdma_get_hw_revision(struct fdma *fdma,
! 		int *major, int *minor)
  {
! 	*major = readl(fdma->io_base + fdma->regs.fdma_id);
! 	*minor = readl(fdma->io_base + fdma->regs.fdma_ver);
  }
  
! #if defined(CONFIG_STM_DMA_FW_KERNEL)
  
! static int fdma_do_bootload(struct fdma *fdma)
  {
! 	device_t *ptr = 0;
! 	struct fdma_fw fw = fdma->fw;
  	unsigned long unused_ibytes;
  	unsigned long unused_dbytes;
  	unsigned long irqflags;
! 	void *addr = (char *)fdma->io_base;
  
! 	fdma_dbg(fdma, "FDMA: Loading Firmware...");
! 	unused_ibytes = fw.imem_len - fw.imem_fw_sz;
! 	unused_dbytes = fw.dmem_len - fw.dmem_fw_sz;
! 
! 	spin_lock_irqsave(&fdma->channels_lock, irqflags);
! 	ptr = (device_t *)((char *)addr + fdma->regs.fdma_dmem_region);
! 	memcpy((void *)ptr, &fw.data_reg[0], fw.dmem_fw_sz * sizeof(u32));
! 	if (unused_dbytes) {
! 		ptr = (device_t *)((char *)addr + fdma->regs.fdma_dmem_region +
! 				(fw.dmem_fw_sz * sizeof(u32)));
! 		memset((void *)ptr, 0, unused_dbytes);
! 	}
! 
! 	ptr = (device_t *)((char *)addr + fdma->regs.fdma_imem_region);
! 	memcpy((void *)ptr, &fw.imem_reg[0], fw.imem_fw_sz * sizeof(u32));
! 	if (unused_ibytes) {
! 		ptr = (device_t *)((char *)addr + fdma->regs.fdma_imem_region +
! 				(fw.imem_fw_sz * sizeof(u32)));
! 		memset((void *)ptr, 0, unused_ibytes);
  	}
! 	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  
! 	fdma->firmware_loaded = 1;
! 	wake_up(&fdma->fw_load_q);
  
  	return 0;
  }
--- 650,703 ----
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! static void fdma_get_fw_revision(struct fdma_dev * fd, int *major, int *minor)
  {
! 	int reg = readl(fd->io_base + fd->regs.fdma_dmem_region);
! 	*major  = (reg & 0xff00) >>8;
! 	*minor  = reg & 0xff;
  }
  
! static void fdma_get_hw_revision(struct fdma_dev * fd, int *major, int *minor)
  {
! 	*major = readl(fd->io_base + fd->regs.fdma_id);
! 	*minor = readl(fd->io_base + fd->regs.fdma_ver);
  }
  
! #if  defined(CONFIG_STM_DMA_FW_KERNEL)
  
! static int fdma_do_bootload(struct fdma_dev * fd)
  {
! 	device_t* ptr=0;
! 	struct fdma_fw fw=fd->fw;
  	unsigned long unused_ibytes;
  	unsigned long unused_dbytes;
  	unsigned long irqflags;
! 	void * addr =(char*)fd->io_base;
  
! 	fdma_dbg(fd, "FDMA: Loading Firmware...");
! 	unused_ibytes= fw.imem_len - fw.imem_fw_sz;
! 	unused_dbytes= fw.dmem_len - fw.dmem_fw_sz;
! 
! 	spin_lock_irqsave(&fd->channel_lock,irqflags);
! 	ptr = (device_t*) ((char*) addr +fd->regs.fdma_dmem_region);
! 	memcpy((void*)ptr,&fw.data_reg[0],fw.dmem_fw_sz * sizeof(u32));
! 	if(unused_dbytes){
! 		ptr =(device_t*) ((char*)addr +fd->regs.fdma_dmem_region
! 				  +(fw.dmem_fw_sz*sizeof(u32)));
! 		memset((void*)ptr ,0, unused_dbytes);
! 	}
! 
! 	ptr = (device_t*) ((char*) addr +fd->regs.fdma_imem_region);
! 	memcpy((void*)ptr,&fw.imem_reg[0],fw.imem_fw_sz* sizeof(u32));
! 	if(unused_ibytes){
! 		ptr =(device_t*) ((char*)addr +fd->regs.fdma_imem_region
! 				  +(fw.imem_fw_sz*sizeof(u32)));
! 		memset((void*)ptr,0, unused_ibytes);
  	}
! 	spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  
! 	fd->firmware_loaded=1;
! 	wake_up(&fd->fw_load_q);
  
  	return 0;
  }
***************
*** 716,866 ****
   * This also means the size parameter is incorrect
   * - Grrrr.
  */
! static void fdma_build_elf_imem(struct fdma *fdma,
! 		struct elf32_shdr *sect_hd,
! 		struct firmware *slimcore_elf)
! {
! 	int pos = 0;
! 	char *file_off = 0;
! 	int imem_sz = sect_hd->sh_size + (sect_hd->sh_size / 3);
! 	u8 *imem_st = kmalloc(imem_sz, GFP_KERNEL);
! 	u8 *imem_ptr = imem_st;
! 	char *imem_sect = (char *)fdma->io_base + fdma->regs.fdma_imem_region;
! 
! 	file_off = (u8 *)&slimcore_elf->data[sect_hd->sh_offset];
! 
! 	do {
! 		memcpy(imem_ptr, file_off, sizeof(char) * 3);
! 		imem_ptr += 3;
! 		file_off += 3;
! 		*imem_ptr = 0x00;
  		imem_ptr++;
! 	} while ((pos += 3) < sect_hd->sh_size);
  
! 	memcpy(imem_sect, imem_st, imem_sz);
  	kfree(imem_ptr);
  }
  
! static void fdma_build_elf_dmem(struct fdma *fdma,
! 		struct elf32_shdr *sect_hd,
! 		struct firmware *slimcore_elf)
  {
! 	char *dmem_sect = (char *)fdma->io_base + fdma->regs.fdma_dmem_region;
! 	char *file_off = 0;
  
! 	file_off = (char *)&slimcore_elf->data[sect_hd->sh_offset];
! 	memcpy(dmem_sect, (char *)file_off, sect_hd->sh_size);
  }
  
  
! static int fdma_do_bootload(struct fdma *fdma)
  {
! 	int err = 0;
! 	int i = 0, imem_loaded = 0, dmem_loaded = 0;
  	char fw_revision[20];
  	char hw_revision[20];
! 	int major = 0, minor = 0;
! 	struct firmware *slimcore_elf = {0};
  	struct elf32_hdr hdr;
  
! 	fdma_dbg(fdma, "FDMA: Loading Firmware ELF...");
  
  	err = request_firmware((const struct firmware **)&slimcore_elf,
! 			fdma->fw_name, &fdma_device_list[fdma->hwid]);
! 	if (err != 0) {
! 		fdma_dbg(fdma, "%s Can't Locate/Load Firmware %s\n",
! 				__FUNCTION__, fdma->fw_name);
  		return -ENOENT;
  	}
  
! 	memcpy(&hdr, slimcore_elf->data, sizeof(struct elf32_hdr));
  
! 	/* build the section header tbl */
! 	for (i = 0; i < hdr.e_shnum; i++) {
  		struct elf32_shdr sect_hdr;
! 		char *sh_addr = (char *)&slimcore_elf->data[hdr.e_shoff +
! 				(i * sizeof(struct elf32_shdr))];
! 		memcpy(&sect_hdr, (char *)sh_addr, sizeof(struct elf32_shdr));
! 
! 		if (SHT_PROGBITS == sect_hdr.sh_type) {
! 			if (sect_hdr.sh_flags & SHF_ALLOC) {
! 				if ((sect_hdr.sh_flags & SHF_EXECINSTR) ==
! 						SHF_EXECINSTR) {
! 					fdma_build_elf_imem(fdma, &sect_hdr,
! 							slimcore_elf);
! 					imem_loaded = 1;
! 				} else if ((sect_hdr.sh_flags & SHF_WRITE) ==
! 						SHF_WRITE) {
! 					fdma_build_elf_dmem(fdma, &sect_hdr,
! 							slimcore_elf);
! 					dmem_loaded = 1;
  				}
  			}
! 			if (dmem_loaded && imem_loaded) {
! 				/* we can discard the remainder of the
! 				 * elf now */
  				break;
  			}
  		}
  	}
  	release_firmware(slimcore_elf);
! 	if (dmem_loaded && imem_loaded) {
! 		fdma->firmware_loaded = 1;
! 		wake_up(&fdma->fw_load_q);
! 	} else {
! 		return -ENODEV;
! 	}
! 
! 	fdma_get_fw_revision(fdma, &fw_revision[0], major, minor);
! 	fdma_get_hw_revision(fdma, &hw_revision[0], major, minor);
! 	fdma_dbg(fdma, "STB_%dC%d %s %s OK\n", fdma->cpu_subtype, fdma->cpu_rev,
! 			hw_revision, fw_revision);
  	return 0;
  }
  #endif
  
! static int fdma_load_firmware(struct fdma *fdma)
  {
! 	unsigned long irqflags = 0;
  	int hw_major, hw_minor;
  	int fw_major, fw_minor;
! 	spin_lock_irqsave(&fdma->channels_lock, irqflags);
! 	switch (fdma->firmware_loaded) {
! 	case 0:
! 		fdma->firmware_loaded = -1;
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
! 		if (fdma_do_bootload(fdma) != 0) {
! 			fdma->firmware_loaded = 0;
! 			return -ENOMEM;
! 		}
! 		fdma_get_hw_revision(fdma, &hw_major, &hw_minor);
! 		fdma_get_fw_revision(fdma, &fw_major, &fw_minor);
! 		fdma_info(fdma, "SLIM hw %d.%d, FDMA fw %d.%d\n",
! 				hw_major, hw_minor, fw_major, fw_minor);
! 
! 		if (fdma_run_initialise_sequence(fdma) != 0)
! 			return -ENODEV;
! 
! 		return (fdma->firmware_loaded == 1) ? 0: -ENODEV;
! 	case 1:
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
! 		return 0;
! 	default:
! 	case -1:
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
! 		wait_event_interruptible(fdma->fw_load_q,
! 				(fdma->firmware_loaded == 1));
! 		if (!fdma->firmware_loaded)
! 			return -ENODEV;
! 		else
  			return 0;
  	}
  	return 0;
  }
  
! static int fdma_check_firmware_state(struct fdma *fdma)
  {
! 	return (fdma->firmware_loaded) ? 0 : fdma_load_firmware(fdma);
  }
  
  /*---------------------------------------------------------------------*
--- 712,856 ----
   * This also means the size parameter is incorrect
   * - Grrrr.
  */
! static void build_elf_imem(	struct fdma_dev * fd,
! 				struct elf32_shdr * sect_hd,
! 				struct firmware * slimcore_elf)
! {
! 	int pos=0;
! 	char * file_off=0;
! 	int imem_sz = sect_hd->sh_size+ (sect_hd->sh_size /3);
! 	u8 * imem_st=  kmalloc(imem_sz,GFP_KERNEL);
! 	u8 * imem_ptr =imem_st;
! 	char * imem_sect = (char*)fd->io_base + fd->regs.fdma_imem_region;
! 
! 	file_off =(u8*) &slimcore_elf->data[sect_hd->sh_offset];
! 
! 	do{
! 		memcpy(imem_ptr,file_off,sizeof(char)*3);
! 		imem_ptr+=3;
! 		file_off+=3;
! 		*imem_ptr=0x00;
  		imem_ptr++;
! 	}while((pos+=3)< sect_hd->sh_size);
  
! 	memcpy(imem_sect,imem_st ,imem_sz);
  	kfree(imem_ptr);
  }
  
! static void build_elf_dmem(	struct fdma_dev * fd,
! 				struct elf32_shdr * sect_hd,
! 				struct firmware * slimcore_elf)
  {
! 	char * dmem_sect = (char*)fd->io_base + fd->regs.fdma_dmem_region;
! 	char * file_off=0;
  
! 	file_off = (char*)&slimcore_elf->data[sect_hd->sh_offset];
! 	memcpy(dmem_sect,(char*)file_off ,sect_hd->sh_size);
  }
  
  
! static int fdma_do_bootload(struct fdma_dev * fd)
  {
! 	int err=0;
! 	int i=0,imem_loaded=0,dmem_loaded=0;
  	char fw_revision[20];
  	char hw_revision[20];
! 	int major=0,minor=0;
! 	struct firmware *slimcore_elf={0};
  	struct elf32_hdr hdr;
  
! 	fdma_dbg(fd, "FDMA: Loading Firmware ELF...");
  
  	err = request_firmware((const struct firmware **)&slimcore_elf,
! 				fd->fw_name,&fdma_device_list[fd->hwid]);
! 	if(err != 0 ){
! 		fdma_dbg(fd, "%s Can't Locate/Load Firmware %s\n",
! 		       __FUNCTION__, fd->fw_name);
  		return -ENOENT;
  	}
  
! 	memcpy(&hdr,slimcore_elf->data,sizeof(struct elf32_hdr));
! 
  
! 	// build the section header tbl
! 	for(i=0;i < hdr.e_shnum;i++){
  		struct elf32_shdr sect_hdr;
! 		char* sh_addr = (char*)&slimcore_elf->data[hdr.e_shoff + (i * sizeof(struct elf32_shdr))];
! 		memcpy(&sect_hdr,(char*)sh_addr ,sizeof(struct elf32_shdr));
! 
! 		if(SHT_PROGBITS== sect_hdr.sh_type){
! 			if(sect_hdr.sh_flags & SHF_ALLOC){
! 
! 				if((sect_hdr.sh_flags & SHF_EXECINSTR) == SHF_EXECINSTR){
! 					build_elf_imem(fd,&sect_hdr,slimcore_elf);
! 					imem_loaded=1;
! 				}
! 				else if((sect_hdr.sh_flags & SHF_WRITE) == SHF_WRITE){
! 					build_elf_dmem(fd,&sect_hdr,slimcore_elf);
! 					dmem_loaded=1;
  				}
  			}
! 			if(dmem_loaded && imem_loaded){
! 				/*we can discard the remainder of the elf now*/
  				break;
  			}
  		}
  	}
  	release_firmware(slimcore_elf);
! 	if(dmem_loaded && imem_loaded){
! 		fd->firmware_loaded=1;
! 		wake_up(&fd->fw_load_q);
! 	}
! 	else return -ENODEV;
! 
! 	fdma_get_fw_revision(fd,&fw_revision[0],major,minor);
! 	fdma_get_hw_revision(fd,&hw_revision[0],major,minor);
! 	fdma_dbg(fd, "STB_%dC%d %s %s OK\n",
! 		 fd->cpu_subtype,fd->cpu_rev,hw_revision,fw_revision);
  	return 0;
  }
  #endif
  
! static int fdma_load_firmware(struct fdma_dev * fd)
  {
! 	unsigned long irqflags=0;
  	int hw_major, hw_minor;
  	int fw_major, fw_minor;
! 	spin_lock_irqsave(&fd->channel_lock,irqflags);
! 	switch ( fd->firmware_loaded ) {
! 		case 0:
! 			fd->firmware_loaded = -1;
! 			spin_unlock_irqrestore(&fd->channel_lock,irqflags);
! 			if (fdma_do_bootload(fd)!=0){
! 				fd->firmware_loaded=0;
! 				return  -ENOMEM;
! 			}
! 			fdma_get_hw_revision(fd, &hw_major, &hw_minor);
! 			fdma_get_fw_revision(fd, &fw_major, &fw_minor);
! 			fdma_info(fd, "SLIM hw %d.%d, FDMA fw %d.%d\n",
! 				  hw_major, hw_minor, fw_major, fw_minor);
! 
! 			if(fdma_run_initialise_sequence(fd)!=0)
! 				return -ENODEV;
! 
! 			return (fd->firmware_loaded==1) ? 0:-ENODEV;
! 		case 1:
! 			spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  			return 0;
+ 		default:
+ 		case -1:
+ 			spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+ 			wait_event_interruptible(fd->fw_load_q,(fd->firmware_loaded==1));
+ 			if(!fd->firmware_loaded)
+ 				return -ENODEV;
+ 			else return 0;
  	}
  	return 0;
  }
  
! static int fdma_check_firmware_state(struct fdma_dev * fd)
  {
! 	return (fd->firmware_loaded) ? 0:fdma_load_firmware(fd);
  }
  
  /*---------------------------------------------------------------------*
***************
*** 869,1006 ****
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! /* returns the number of bytes left to transfer for the current node */
! static int fdma_get_residue(struct dma_channel *dma_chan)
  {
! 	struct fdma_channel *channel = dma_chan->priv_data;
! 	struct fdma *fdma = channel->fdma;
! 	struct stm_dma_params *params = channel->params;
  	unsigned long irqflags;
! 	u32 count = 0;
  
! 	spin_lock_irqsave(&fdma->channels_lock, irqflags);
  
! 	if (likely(channel->sw_state != FDMA_IDLE)) {
! 		struct fdma_xfer_descriptor *desc =
! 			(struct fdma_xfer_descriptor *)params->priv;
! 		void __iomem *chan_base = fdma->io_base +
! 				(channel->chan_num * NODE_DATA_OFFSET);
! 		unsigned long current_node_phys;
! 		unsigned long stat1, stat2;
! 		struct fdma_llu_node *current_node;
! 		int node_num;
! 
! 		/* Get info about current node */
! 		do {
! 			stat1 = readl(CMD_STAT_REG(channel->chan_num));
! 			count = readl(chan_base + fdma->regs.fdma_cntn);
! 			stat2 = readl(CMD_STAT_REG(channel->chan_num));
! 		} while (stat1 != stat2);
! 
! 		current_node_phys = stat1 & ~0x1f;
! 		for (node_num = 0, current_node = desc->llu_nodes;
! 				current_node->dma_addr != current_node_phys;
! 				node_num++, current_node++)
! 			BUG_ON(node_num == desc->alloced_nodes);
! 
! 		switch (stat1 & 3) {
! 		case FDMA_CHANNEL_IDLE:
! 			/* Channel has stopped, but we haven't taken
! 			 * the interrupt to change the ->sw_state
! 			 * field yet. We could legitimatly return zero
! 			 * here, but instead pretend we haven't quite
! 			 * finished yet. Is this the right thing to
! 			 * do? */
! 			count = 1;
! 			goto unlock;
! 
! 		case FDMA_CHANNEL_RUNNING:
! 		case FDMA_CHANNEL_PAUSED:
! 			/* Unfortuntaly the firmware appears to modify
! 			 * CMD_STAT before it has modifed the COUNT.
! 			 * However we write the count in
! 			 * fdma_start_channel() so can assume it is
! 			 * valid. */
! 			break;
  
! 		case CMDSTAT_FDMA_START_CHANNEL:
! 			/* Channel hasn't started running yet, so count
! 			 * hasn't yet been loaded from the node. But again
! 			 * the value was written in fdma_start_channel()
! 			 * so the value read from hardware is valid. */
! 			break;
! 		}
! 
! 		while (++node_num < desc->alloced_nodes) {
! 			current_node++;
! 			count += current_node->virt_addr->size_bytes;
! 		}
  	}
  
! unlock:
! 	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  
  	return count;
  }
  
! /* must only be called when channel is in paused state */
! static int fdma_unpause(struct fdma_channel *channel)
  {
! 	struct fdma *fdma = channel->fdma;
! 	unsigned long irqflags = 0;
  	u32 cmd_sta_value;
  
! 	spin_lock_irqsave(&fdma->channels_lock, irqflags);
! 	if (channel->sw_state != FDMA_PAUSED) {
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  		return -EBUSY;
  	}
  
! 	cmd_sta_value = readl(CMD_STAT_REG(channel->chan_num));
  	cmd_sta_value &= ~CMDSTAT_FDMA_CMD_MASK;
  	cmd_sta_value |= CMDSTAT_FDMA_RESTART_CHANNEL;
! 	writel(cmd_sta_value, CMD_STAT_REG(channel->chan_num));
  
! 	writel(MBOX_CMD_START_CHANNEL << (channel->chan_num * 2),
! 			fdma->io_base + fdma->regs.fdma_cmd_set);
! 	channel->sw_state = FDMA_RUNNING;
  
! 	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  	return 0;
  }
  
! static int fdma_pause(struct fdma_channel *channel, int flush)
  {
! 	struct fdma *fdma = channel->fdma;
! 	unsigned long irqflags = 0;
  
! 	spin_lock_irqsave(&fdma->channels_lock, irqflags);
! 	switch (channel->sw_state) {
  	case FDMA_IDLE:
  	case FDMA_CONFIGURED:
  		/* Hardware isn't set up yet, so treat this as an error */
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  		return -EBUSY;
  	case FDMA_PAUSED:
  		/* Hardware is already paused */
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  		return 0;
  	case FDMA_RUNNING:
  		/* Hardware is running, send the command */
  		writel((flush ? MBOX_CMD_FLUSH_CHANNEL : MBOX_CMD_PAUSE_CHANNEL)
! 				<< (channel->chan_num * 2),
! 				fdma->io_base + fdma->regs.fdma_cmd_set);
  		/* Fall through */
  	case FDMA_PAUSING:
  	case FDMA_STOPPING:
  		/* Hardware is pausing already, wait for interrupt */
! 		channel->sw_state = FDMA_PAUSING;
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  #if 0
  		/* In some cases this is called from a context which cannot
  		 * block, so disable the wait at the moment. */
! 		wait_event(channel->cur_cfg->wait_queue,
! 				channel->sw_state == FDMA_PAUSED);
  #endif
  		break;
  	}
--- 859,950 ----
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! /*returns the number of bytes left to transfer for the current node*/
! static  int stb710x_fdma_get_residue(struct dma_channel *chan)
  {
! 	struct fdma_dev *fd = FDMA_DEV(chan);
! 	void __iomem *chan_base = fd->io_base + (chan->chan * NODE_DATA_OFFSET);
  	unsigned long irqflags;
! 	unsigned long count;
! 	fdma_llu_entry *current_node, *next_node;
  
! 	spin_lock_irqsave(&fd->channel_lock, irqflags);
  
! 	/* Get info about current node */
! 	current_node = (fdma_llu_entry *)phys_to_virt(readl(CMD_STAT_REG(chan->chan)) & ~0x1f);
! 	count = readl(chan_base + fd->regs.fdma_cntn);
  
! 	/* Accumulate the bytes remaining in the list */
! 	next_node = (fdma_llu_entry *)phys_to_virt(readl(chan_base + fd->regs.fdma_ptrn));
! 	while (next_node && next_node > current_node) {
! 		count += next_node->size_bytes;
! 		next_node = (fdma_llu_entry *)phys_to_virt(next_node->next_item);
  	}
  
! 	spin_unlock_irqrestore(&fd->channel_lock, irqflags);
  
  	return count;
  }
  
! /*must only be called when channel is in pasued state*/
! static int stb710x_fdma_unpause(struct fdma_dev * fd,struct dma_channel * channel)
  {
! 	struct channel_status *chan = FDMA_CHAN(channel);
! 	unsigned long irqflags=0;
  	u32 cmd_sta_value;
  
! 	spin_lock_irqsave(&fd->channel_lock,irqflags);
! 	if (chan->sw_state != FDMA_PAUSED) {
! 		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  		return -EBUSY;
  	}
  
! 	cmd_sta_value = readl(CMD_STAT_REG(channel->chan));
  	cmd_sta_value &= ~CMDSTAT_FDMA_CMD_MASK;
  	cmd_sta_value |= CMDSTAT_FDMA_RESTART_CHANNEL;
! 	writel(cmd_sta_value, CMD_STAT_REG(channel->chan));
  
! 	writel(MBOX_CMD_START_CHANNEL << (channel->chan*2),
! 	       fd->io_base + fd->regs.fdma_cmd_set);
! 	chan->sw_state = FDMA_RUNNING;
  
! 	spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  	return 0;
  }
  
! static int stb710x_fdma_pause(struct fdma_dev * fd,
! 		struct dma_channel * channel,
! 		int flush)
  {
! 	struct channel_status *chan = FDMA_CHAN(channel);
! 	unsigned long irqflags=0;
  
! 	spin_lock_irqsave(&fd->channel_lock,irqflags);
! 	switch (chan->sw_state) {
  	case FDMA_IDLE:
  	case FDMA_CONFIGURED:
  		/* Hardware isn't set up yet, so treat this as an error */
! 		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  		return -EBUSY;
  	case FDMA_PAUSED:
  		/* Hardware is already paused */
! 		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  		return 0;
  	case FDMA_RUNNING:
  		/* Hardware is running, send the command */
  		writel((flush ? MBOX_CMD_FLUSH_CHANNEL : MBOX_CMD_PAUSE_CHANNEL)
! 						<< (channel->chan*2), fd->io_base + fd->regs.fdma_cmd_set);
  		/* Fall through */
  	case FDMA_PAUSING:
  	case FDMA_STOPPING:
  		/* Hardware is pausing already, wait for interrupt */
! 		chan->sw_state = FDMA_PAUSING;
! 		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  #if 0
  		/* In some cases this is called from a context which cannot
  		 * block, so disable the wait at the moment. */
! 		wait_event(chan->cur_cfg->wait_queue,
! 			   chan->sw_state == FDMA_PAUSED);
  #endif
  		break;
  	}
***************
*** 1008,1055 ****
  	return 0;
  }
  
! static int fdma_request(struct dma_channel *dma_chan)
  {
! 	struct fdma_channel *channel = dma_chan->priv_data;
! 	struct fdma *fdma = channel->fdma;
  
! 	if (fdma_check_firmware_state(fdma) == 0)
  		return 0;
  
! 	return -ENOSYS;
  }
  
! static int fdma_stop(struct fdma_channel *channel)
  {
! 	struct fdma *fdma = channel->fdma;
! 	unsigned long cmd_val = MBOX_CMD_PAUSE_CHANNEL <<
! 			(channel->chan_num * 2);
! 	unsigned long irqflags = 0;
  
! 	spin_lock_irqsave(&fdma->channels_lock, irqflags);
! 	switch (channel->sw_state) {
  	case FDMA_IDLE:
  	case FDMA_CONFIGURED:
  	case FDMA_PAUSED:
  		/* Hardware is already idle, simply change state */
! 		channel->sw_state = FDMA_IDLE;
! 		writel(0, CMD_STAT_REG(channel->chan_num));
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  		break;
  	case FDMA_RUNNING:
  		/* Hardware is running, send the command */
! 		writel(cmd_val, fdma->io_base + fdma->regs.fdma_cmd_set);
  		/* Fall through */
  	case FDMA_PAUSING:
  	case FDMA_STOPPING:
  		/* Hardware is pausing already, wait for interrupt */
! 		channel->sw_state = FDMA_STOPPING;
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  #if 0
  		/* In some cases this is called from a context which cannot
  		 * block, so disable the wait at the moment. */
! 		wait_event(channel->cur_cfg->wait_queue,
! 				channel->sw_state == FDMA_IDLE);
  #endif
  		break;
  	}
--- 952,998 ----
  	return 0;
  }
  
! static int stb710x_fdma_request(struct dma_channel *channel)
  {
! 	struct fdma_dev *fd = FDMA_DEV(channel);
  
! 	if(fdma_check_firmware_state(fd)==0){
  		return 0;
+ 	}
  
! 	return ENOSYS;
  }
  
! static int stb710x_fdma_stop(struct fdma_dev * fd,struct dma_channel *channel)
  {
! 	struct channel_status *chan = FDMA_CHAN(channel);
! 	unsigned long cmd_val = (MBOX_CMD_PAUSE_CHANNEL << (channel->chan*2));
! 	unsigned long irqflags=0;
  
! 	spin_lock_irqsave(&fd->channel_lock,irqflags);
! 	switch (chan->sw_state) {
  	case FDMA_IDLE:
  	case FDMA_CONFIGURED:
  	case FDMA_PAUSED:
  		/* Hardware is already idle, simply change state */
! 		chan->sw_state = FDMA_IDLE;
! 		writel(0,CMD_STAT_REG(channel->chan));
! 		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  		break;
  	case FDMA_RUNNING:
  		/* Hardware is running, send the command */
! 		writel(cmd_val,(fd->io_base +fd->regs.fdma_cmd_set));
  		/* Fall through */
  	case FDMA_PAUSING:
  	case FDMA_STOPPING:
  		/* Hardware is pausing already, wait for interrupt */
! 		chan->sw_state = FDMA_STOPPING;
! 		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
  #if 0
  		/* In some cases this is called from a context which cannot
  		 * block, so disable the wait at the moment. */
! 		wait_event(chan->cur_cfg->wait_queue,
! 			   chan->sw_state == FDMA_IDLE);
  #endif
  		break;
  	}
***************
*** 1057,1071 ****
  	return 0;
  }
  
! static int fdma_free_params(struct stm_dma_params *params)
  {
! 	struct fdma *fdma = params->params_ops_priv;
  	struct stm_dma_params *this;
  
  	for (this = params; this; this = this->next) {
! 		struct fdma_xfer_descriptor *desc = this->priv;
  		if (desc) {
! 			fdma_resize_nodelist_mem(fdma, desc, 0, 0);
  			kfree(desc);
  		}
  	}
--- 1000,1014 ----
  	return 0;
  }
  
! static int stb710x_fdma_free_params(struct stm_dma_params *params)
  {
! 	struct fdma_dev * fd = params->params_ops_priv;
  	struct stm_dma_params *this;
  
  	for (this = params; this; this = this->next) {
! 		struct dma_xfer_descriptor *desc = (struct dma_xfer_descriptor*)this->priv;
  		if (desc) {
! 			resize_nodelist_mem(fd, desc, 0, 0);
  			kfree(desc);
  		}
  	}
***************
*** 1074,1171 ****
  }
  
  static struct params_ops fdma_params_ops = {
! 	.free_params = fdma_free_params
  };
  
  /* Compile params part 1: generate template nodes */
! static int fdma_compile1(struct fdma *fdma, struct stm_dma_params *params)
  {
  	struct stm_dma_params *this;
  
  	for (this = params; this; this = this->next) {
! 		struct fdma_xfer_descriptor *desc = this->priv;
  
  		if (desc != NULL)
  			continue;
  
! 		desc = kzalloc(sizeof(struct fdma_xfer_descriptor),
! 				params->context);
  		if (desc == NULL)
  			return -ENOMEM;
  		this->priv = desc;
  
! 		if (this->mode == MODE_SRC_SCATTER)
! 			desc->extrapolate_fn = fdma_extrapolate_sg_src;
! 		else if (this->mode == MODE_DST_SCATTER)
! 			desc->extrapolate_fn = fdma_extrapolate_sg_dst;
! 		else
! 			desc->extrapolate_fn = fdma_extrapolate_simple;
  
! 		if (this->mode == MODE_PACED)
! 			fdma_setup_paced_node(this, &desc->template_llu);
! 		else
! 			fdma_setup_freerunning_node(this, &desc->template_llu);
  
  		/* For any 1D transfers, line_len = nbytes */
! 		desc->extrapolate_line_len = !((DIM_SRC(this->dim) == 2) ||
! 				(DIM_DST(this->dim) == 2));
  	}
  
  	return 0;
  }
  
  /* Compile params part 2: allocate node list */
! static int fdma_compile2(struct fdma *fdma, struct stm_dma_params *params)
  {
  	struct stm_dma_params *this;
  	int numnodes = 0;
! 	struct fdma_xfer_descriptor *desc;
  
  	for (this = params; this; this = this->next) {
! 		if (this->mode == MODE_SRC_SCATTER ||
! 				this->mode == MODE_DST_SCATTER)
  			numnodes += this->sglen;
  		else
  			numnodes++;
  	}
  
! 	desc = params->priv;
  	if (desc->alloced_nodes < numnodes) {
! 		int err = fdma_resize_nodelist_mem(fdma, desc, numnodes,
! 				params->context);
! 
! 		if (err)
! 			return err;
  	}
  
  	return 0;
  }
  
  /* Compile params part 3: extrapolate */
! static int fdma_compile3(struct fdma *fdma, struct stm_dma_params *params)
  {
  	struct stm_dma_params *this;
! 	struct fdma_xfer_descriptor *this_desc;
! 	struct fdma_llu_node *first_node, *last_node, *node;
  
  	this = params;
! 	this_desc = (struct fdma_xfer_descriptor *)this->priv;
  	first_node = this_desc->llu_nodes;
  
  	node = first_node;
  	while (1) {
  		last_node = this_desc->extrapolate_fn(this, this_desc, node);
  
  		this = this->next;
  		if (this == NULL)
  			break;
  
! 		this_desc = (struct fdma_xfer_descriptor *)this->priv;
  		node = last_node + 1;
  		last_node->virt_addr->next_item = node->dma_addr;
  	}
  
! 	if (params->circular_llu)
  		last_node->virt_addr->next_item = first_node->dma_addr;
  	else
  		last_node->virt_addr->next_item = 0;
--- 1017,1117 ----
  }
  
  static struct params_ops fdma_params_ops = {
! 	.free_params	= stb710x_fdma_free_params
  };
  
  /* Compile params part 1: generate template nodes */
! static int _compile1(struct fdma_dev * fd,struct stm_dma_params *params)
  {
  	struct stm_dma_params *this;
  
  	for (this = params; this; this = this->next) {
! 		struct dma_xfer_descriptor *desc;
  
+ 		desc = (struct dma_xfer_descriptor*)this->priv;
  		if (desc != NULL)
  			continue;
  
! 		desc = kzalloc(sizeof(struct dma_xfer_descriptor), params->context);
  		if (desc == NULL)
  			return -ENOMEM;
  		this->priv = desc;
  
! 		if (IS_TRANSFER_SG(this)){
! 			if(MODE_SRC_SCATTER==this->mode)
! 				desc->extrapolate_fn = extrapolate_sg_src;
! 			else if(MODE_DST_SCATTER==this->mode)
! 				desc->extrapolate_fn = extrapolate_sg_dst;
! 			else return -EINVAL;
! 		} else {
! 			desc->extrapolate_fn = extrapolate_simple;
! 		}
  
! 		if(this->mode == MODE_PACED){
! 			setup_paced_node(this, &desc->template_llu);
! 		} else {
! 			setup_freerunning_node(this, &desc->template_llu);
! 		}
  
  		/* For any 1D transfers, line_len = nbytes */
! 		desc->extrapolate_line_len =
! 			!((DIM_SRC(this->dim) == 2) || (DIM_DST(this->dim) == 2));
  	}
  
  	return 0;
  }
  
  /* Compile params part 2: allocate node list */
! static int _compile2(struct fdma_dev * fd,struct stm_dma_params *params)
  {
  	struct stm_dma_params *this;
  	int numnodes = 0;
! 	struct dma_xfer_descriptor *desc;
  
  	for (this = params; this; this = this->next) {
! 		if (IS_TRANSFER_SG(this))
  			numnodes += this->sglen;
  		else
  			numnodes++;
  	}
  
! 	desc = (struct dma_xfer_descriptor*)params->priv;
  	if (desc->alloced_nodes < numnodes) {
! 		int res;
! 		res = resize_nodelist_mem(fd, desc, numnodes, params->context);
! 		if (res)
! 			return res;
  	}
  
  	return 0;
  }
  
  /* Compile params part 3: extrapolate */
! static int _compile3(struct fdma_dev * fd,struct stm_dma_params *params)
  {
  	struct stm_dma_params *this;
! 	struct dma_xfer_descriptor *this_desc;
! 	struct llu_node *first_node, *last_node, *node;
  
  	this = params;
! 	this_desc = (struct dma_xfer_descriptor*)this->priv;
  	first_node = this_desc->llu_nodes;
  
  	node = first_node;
  	while (1) {
+ 
  		last_node = this_desc->extrapolate_fn(this, this_desc, node);
  
  		this = this->next;
  		if (this == NULL)
  			break;
  
! 		this_desc = (struct dma_xfer_descriptor*)this->priv;
  		node = last_node + 1;
  		last_node->virt_addr->next_item = node->dma_addr;
  	}
  
! 	if(params->circular_llu)
  		last_node->virt_addr->next_item = first_node->dma_addr;
  	else
  		last_node->virt_addr->next_item = 0;
***************
*** 1173,1309 ****
  	return 0;
  }
  
! static int fdma_compile_params(struct fdma_channel *channel,
! 		struct stm_dma_params *params)
  {
- 	struct fdma *fdma = channel->fdma;
  	int res;
  
! 	res = fdma_compile1(fdma, params);
  	if (res)
  		return res;
  
! 	res = fdma_compile2(fdma, params);
  	if (res)
  		return res;
  
! 	res = fdma_compile3(fdma, params);
  	if (res == 0) {
  		params->params_ops = &fdma_params_ops;
! 		params->params_ops_priv = fdma;
  	}
  
  	return res;
  }
  
! static void fdma_free(struct dma_channel *dma_chan)
  {
! 	struct fdma_channel *channel = dma_chan->priv_data;
! 	struct fdma *fdma = channel->fdma;
! 	unsigned long irq_flags = 0;
  
! 	spin_lock_irqsave(&fdma->channels_lock, irq_flags);
  
! 	if (channel->sw_state != FDMA_IDLE) {
! 		spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
! 		fdma_dbg(fdma, "%s channel not idle\n", __FUNCTION__);
  		return;
  	}
  
! 	BUG_ON(fdma_get_engine_status(channel) != FDMA_CHANNEL_IDLE);
  
! 	spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
  }
  
  /* Note although this returns an int, the dma-api code throws this away. */
! static int fdma_configure(struct dma_channel *dma_chan,
! 		unsigned long flags)
  {
! 	struct fdma_channel *channel = dma_chan->priv_data;
! 	struct fdma *fdma = channel->fdma;
! 	struct stm_dma_params *params = (struct stm_dma_params *)flags;
! 	unsigned long irq_flags = 0;
! 
! 	spin_lock_irqsave(&fdma->channels_lock, irq_flags);
! 	if (channel->sw_state != FDMA_IDLE) {
! 		spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
! 		fdma_dbg(fdma, "%s channel not idle\n", __FUNCTION__);
  		return -EBUSY;
  	}
  
! 	if (!((struct fdma_xfer_descriptor *)(params->priv))->llu_nodes) {
! 		fdma_dbg(fdma, "%s no nodelist alloced\n", __FUNCTION__);
! 		spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
  		return -ENOMEM;
  	}
  
! 	/* Now we are associating the compiled transfer llu & params to the
! 	 * channel */
! 	channel->params = params;
! 	tasklet_init(&channel->fdma_complete, params->comp_cb,
! 			(unsigned long)params->comp_cb_parm);
! 	tasklet_init(&channel->fdma_error, params->err_cb,
! 			(unsigned long)params->err_cb_parm);
! 	channel->sw_state = FDMA_CONFIGURED;
  
! 	spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
  
  	return 0;
  }
  
! static int fdma_xfer(struct dma_channel *dma_chan,
! 		unsigned long sar, unsigned long dar,
! 		size_t count, unsigned int mode)
! {
! 	struct fdma_channel *channel = dma_chan->priv_data;
! 	struct fdma *fdma = channel->fdma;
! 	struct fdma_xfer_descriptor *desc;
! 	unsigned long irqflags = 0;
  
! 	/* we need to check that the compile has been completed */
! 	spin_lock_irqsave(&fdma->channels_lock, irqflags);
  
! 	if (channel->sw_state != FDMA_CONFIGURED) {
! 		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  		return -EINVAL;
  	}
  
! 	desc = (struct fdma_xfer_descriptor *)channel->params->priv;
  
! 	BUG_ON(fdma_get_engine_status(channel) != FDMA_CHANNEL_IDLE);
  
! 	fdma_start_channel(channel, desc->llu_nodes->dma_addr,
! 			desc->llu_nodes->virt_addr->size_bytes);
! 	channel->sw_state = FDMA_RUNNING;
  
! 	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
  
  	return 0;
  }
  
! static int fdma_extended(struct dma_channel *dma_chan,
! 		unsigned long opcode, void *ext_param)
  {
! 	struct fdma_channel *channel = dma_chan->priv_data;
! 
! 	switch (opcode) {
  		case STM_DMA_OP_FLUSH:
! 			return fdma_pause(channel, 1);
  		case STM_DMA_OP_PAUSE:
! 			return fdma_pause(channel, 0);
  		case STM_DMA_OP_UNPAUSE:
! 			return fdma_unpause(channel);
  		case STM_DMA_OP_STOP:
! 			return fdma_stop(channel);
  		case STM_DMA_OP_COMPILE:
! 			return fdma_compile_params(channel, ext_param);
  		case STM_DMA_OP_STATUS:
! 			return fdma_get_engine_status(channel);
  		case STM_DMA_OP_REQ_CONFIG:
! 			return (int)fdma_configure_pace_channel(channel,
! 					ext_param);
  		case STM_DMA_OP_REQ_FREE:
! 			fdma_req_free(ext_param);
  			return 0;
  		default:
  			return -ENOSYS;
--- 1119,1254 ----
  	return 0;
  }
  
! static int stb710x_fdma_compile_params(struct fdma_dev * fd,struct stm_dma_params *params)
  {
  	int res;
  
! 	res = _compile1(fd, params);
  	if (res)
  		return res;
  
! 	res = _compile2(fd, params);
  	if (res)
  		return res;
  
! 	res = _compile3(fd, params);
  	if (res == 0) {
  		params->params_ops = &fdma_params_ops;
! 		params->params_ops_priv = fd;
  	}
  
  	return res;
  }
  
! static void stb710x_fdma_free(struct dma_channel *channel)
  {
! 	struct fdma_dev *fd = FDMA_DEV(channel);
! 	struct channel_status *chan = FDMA_CHAN(channel);
! 	unsigned long irq_flags=0;
  
! 	spin_lock_irqsave(&fd->channel_lock,irq_flags);
  
! 	if (chan->sw_state != FDMA_IDLE) {
! 		spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
! 		fdma_dbg(fd, "%s channel not idle\n",__FUNCTION__);
  		return;
  	}
  
! 	BUG_ON(!(IS_CHANNEL_IDLE(fd,channel->chan)));
  
! 	spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
  }
  
  /* Note although this returns an int, the dma-api code throws this away. */
! static int stb710x_fdma_configure(	struct dma_channel *channel,
! 				  	unsigned long flags)
  {
! 	struct fdma_dev *fd = FDMA_DEV(channel);
! 	struct channel_status *chan = FDMA_CHAN(channel);
! 	struct stm_dma_params * params;
! 	unsigned long irq_flags=0;
! 
! 	spin_lock_irqsave(&fd->channel_lock,irq_flags);
! 	if (chan->sw_state != FDMA_IDLE) {
! 		spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
! 		fdma_dbg(fd, "%s channel not idle\n",__FUNCTION__);
  		return -EBUSY;
  	}
  
! 	params = (struct stm_dma_params *)flags;
! 	if(!((struct dma_xfer_descriptor*)(params->priv))->llu_nodes){
! 		fdma_dbg(fd, "%s no nodelist alloced\n",__FUNCTION__);
! 		spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
  		return -ENOMEM;
  	}
  
! 	/* Now we are associating the compiled transfer llu & params to the channel*/
! 	chan->params = params;
! 	tasklet_init(&chan->fdma_complete,
! 		     params->comp_cb, (unsigned long)params->comp_cb_parm);
! 	tasklet_init(&chan->fdma_error,
! 		     params->err_cb, (unsigned long)params->err_cb_parm);
! 	chan->sw_state = FDMA_CONFIGURED;
  
! 	spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
  
  	return 0;
  }
  
! static int stb710x_fdma_xfer(
! 				struct dma_channel *channel,
! 				unsigned long sar,
! 			     	unsigned long dar,
! 			     	size_t count,
! 			     	unsigned int mode)
! {
! 	struct fdma_dev *fd = FDMA_DEV(channel);
! 	struct channel_status *chan = FDMA_CHAN(channel);
! 	struct dma_xfer_descriptor *desc;
! 	unsigned long irqflags=0;
  
! 	/*we need to check that the compile has been completed*/
! 	spin_lock_irqsave(&fd->channel_lock, irqflags);
  
! 	if (chan->sw_state != FDMA_CONFIGURED) {
! 		spin_unlock_irqrestore(&fd->channel_lock, irqflags);
  		return -EINVAL;
  	}
  
! 	desc = (struct dma_xfer_descriptor*)chan->params->priv;
  
! 	BUG_ON(!(IS_CHANNEL_IDLE(fd,channel->chan)));
  
! 	fdma_start_channel(fd,channel->chan, desc->llu_nodes->dma_addr);
! 	chan->sw_state = FDMA_RUNNING;
  
! 	spin_unlock_irqrestore(&fd->channel_lock, irqflags);
  
  	return 0;
  }
  
! static int stb710x_fdma_extended_op(struct dma_channel *  ch,
! 				    unsigned long opcode,
! 				    void * parm)
  {
! 	struct fdma_dev *fd = FDMA_DEV(ch);
! 	switch(opcode){
  		case STM_DMA_OP_FLUSH:
! 			return stb710x_fdma_pause(fd,ch,1);
  		case STM_DMA_OP_PAUSE:
! 			return stb710x_fdma_pause(fd,ch,0);
  		case STM_DMA_OP_UNPAUSE:
! 			return  stb710x_fdma_unpause(fd,ch);
  		case STM_DMA_OP_STOP:
! 			return stb710x_fdma_stop(fd,ch);
  		case STM_DMA_OP_COMPILE:
! 			return stb710x_fdma_compile_params(fd, (struct stm_dma_params *)parm);
  		case STM_DMA_OP_STATUS:
! 			return stb710x_get_engine_status(fd,ch->chan);
  		case STM_DMA_OP_REQ_CONFIG:
! 			return (int)stb710x_configure_pace_channel(fd, ch, (struct stm_dma_req_config *)parm);
  		case STM_DMA_OP_REQ_FREE:
! 			fdma_req_free((struct stm_dma_req *)parm);
  			return 0;
  		default:
  			return -ENOSYS;
***************
*** 1316,1432 ****
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! static struct dma_ops fdma_ops = {
! 	.request	= fdma_request,
! 	.free		= fdma_free,
! 	.get_residue	= fdma_get_residue,
! 	.xfer		= fdma_xfer,
! 	.configure	= fdma_configure,
! 	.extend		= fdma_extended,
  };
  
  static int __init fdma_driver_probe(struct platform_device *pdev)
  {
! 	struct fdma_platform_device_data *plat_data;
! 	struct fdma *fdma = NULL;
  	struct resource *res;
! 	int chan_num;
! 	int err = 0;
  
  	plat_data = pdev->dev.platform_data;
  
! 	fdma = kzalloc(sizeof(struct fdma), GFP_KERNEL);
! 	if (fdma == NULL)
  		return -ENOMEM;
  
  	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
! 	if (!res)
  		return -ENODEV;
  
! 	fdma->phys_mem = request_mem_region(res->start,
! 			res->end - res->start + 1, pdev->name);
! 	if (fdma->phys_mem == NULL)
  		return -EBUSY;
  
! 	fdma->io_base = ioremap_nocache(res->start, res->end - res->start + 1);
! 	if (fdma->io_base == NULL)
  		return -EINVAL;
  
! 	fdma->ch_min = plat_data->min_ch_num;
! 	fdma->ch_max = plat_data->max_ch_num;
! 	fdma->fdma_num = pdev->id;
! 	fdma->ch_status_mask = ((1ULL << ((fdma->ch_max + 1) * 2)) - 1ULL) ^
! 			((1 << (fdma->ch_min * 2)) - 1);
! 
! 	memcpy(&fdma->regs, (u32 *)plat_data->registers_ptr,
! 			sizeof(struct fdma_regs));
! 	fdma->fw_name = plat_data->fw_device_name;
! 	fdma->fw = plat_data->fw;
  
  	/* 7200: Req lines 0 and 31 are connected internally, not to the xbar */
! 	fdma->req_lines_inuse = (1 << 31) | (1 << 0);
  
! 	spin_lock_init(&(fdma)->channels_lock);
! 	init_waitqueue_head(&(fdma)->fw_load_q);
  
! 	fdma->dma_info.nr_channels = fdma->ch_max - fdma->ch_min + 1;
! 	fdma->dma_info.ops = &fdma_ops;
! 	fdma->dma_info.flags = DMAC_CHANNELS_TEI_CAPABLE;
! 	strlcpy(fdma->name, STM_DMAC_ID, FDMA_NAME_LEN);
  	if (pdev->id != -1) {
! 		int len = strlen(fdma->name);
! 		snprintf(fdma->name + len, FDMA_NAME_LEN - len, ".%d",
! 				pdev->id);
  	}
! 	fdma->dma_info.name = fdma->name;
! 
! 	if (register_dmac(&fdma->dma_info) != 0)
! 		printk(KERN_ERR "%s Error Registering DMAC\n", __FUNCTION__);
  
! 	for (chan_num = fdma->ch_min; chan_num <= fdma->ch_max; chan_num++) {
! 		struct fdma_channel *channel = &fdma->channels[chan_num];
! 		struct dma_channel *dma_chan;
  
! 		channel->chan_num = chan_num;
! 		channel->fdma = fdma;
! 
! 		dma_chan = get_dma_channel(chan_num - fdma->ch_min);
! 		dma_chan->priv_data = channel;
! 		channel->dma_chan = dma_chan;
  	}
  
! 	err = request_irq(platform_get_irq(pdev, 0), fdma_irq,
! 			 IRQF_DISABLED | IRQF_SHARED, fdma->name, fdma);
! 	if (err < 0)
! 		panic("Cant Register irq %d for FDMA engine err %d\n",
! 				fdma->irq, err);
  
! 	fdma_register_caps(fdma);
  
! 	fdma_check_firmware_state(fdma);
  
! 	platform_set_drvdata(pdev, fdma);
  
  	return 0;
  }
  
  static int fdma_driver_remove(struct platform_device *pdev)
  {
! 	struct fdma *fdma = platform_get_drvdata(pdev);
  
! 	fdma_disable_all_channels(fdma);
! 	iounmap(fdma->io_base);
! 	dma_pool_destroy(fdma->llu_pool);
! 	free_irq(fdma->irq, fdma);
! 	unregister_dmac(&fdma->dma_info);
! 	release_resource(fdma->phys_mem);
! 	kfree(fdma);
  
  	return 0;
  }
  
  static struct platform_driver fdma_driver = {
! 	.driver.name = "stmfdma",
  	.probe = fdma_driver_probe,
  	.remove = fdma_driver_remove,
  };
--- 1261,1383 ----
   *---------------------------------------------------------------------*
   *---------------------------------------------------------------------*/
  
! static struct dma_ops stb710x_fdma_ops = {
! 	.request		= stb710x_fdma_request,
! 	.free			= stb710x_fdma_free,
! 	.get_residue		= stb710x_fdma_get_residue,
! 	.xfer			= stb710x_fdma_xfer,
! 	.configure		= stb710x_fdma_configure,
! 	.extend			= stb710x_fdma_extended_op,
  };
  
  static int __init fdma_driver_probe(struct platform_device *pdev)
  {
! 	struct fdma_platform_device_data * plat_data;
! 	struct fdma_dev *fd=NULL;
  	struct resource *res;
! 	int i=0;
! 	int err=0;
  
  	plat_data = pdev->dev.platform_data;
  
! 	fd = kzalloc(sizeof(struct fdma_dev), GFP_KERNEL);
! 	if (fd == NULL) {
  		return -ENOMEM;
+ 	};
  
  	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
! 	if (!res) {
  		return -ENODEV;
+ 	}
  
! 	fd->phys_mem = request_mem_region(res->start, res->end - res->start + 1,
! 					  pdev->name);
! 	if (fd->phys_mem == NULL) {
  		return -EBUSY;
+ 	};
  
! 	fd->io_base = ioremap_nocache(res->start, res->end - res->start + 1);
! 	if (fd->io_base == NULL) {
  		return -EINVAL;
+ 	}
  
! 	fd->ch_min = plat_data->min_ch_num;
! 	fd->ch_max = plat_data->max_ch_num;
! 	fd->fdma_num = pdev->id;
! 	fd->ch_status_mask =
! 		((1ULL << (fd->ch_max*2)) - 1ULL) ^
! 		((1    << (fd->ch_min*2)) - 1);
! 
! 	memcpy(&fd->regs,(u32*)plat_data->registers_ptr,sizeof(struct fdma_regs));
! 	fd->fw_name = plat_data->fw_device_name;
! 	fd->fw = plat_data->fw;
  
  	/* 7200: Req lines 0 and 31 are connected internally, not to the xbar */
! 	fd->req_lines_inuse = (1<<31) | (1<<0);
  
! 	spin_lock_init(&(fd)->channel_lock);
! 	init_waitqueue_head(&(fd)->fw_load_q);
  
! 	fd->dma_info.nr_channels = (fd->ch_max+1) - fd->ch_min;
! 	fd->dma_info.ops	= &stb710x_fdma_ops;
! 	fd->dma_info.flags	= DMAC_CHANNELS_TEI_CAPABLE;
! 	strlcpy(fd->name, STM_DMAC_ID, FDMA_NAME_LEN);
  	if (pdev->id != -1) {
! 		int len=strlen(fd->name);
! 		snprintf(fd->name+len, FDMA_NAME_LEN-len, ".%d", pdev->id);
  	}
! 	fd->dma_info.name = fd->name;
  
! 	if(register_dmac(&fd->dma_info)!=0)
! 		printk("%s Error Registering DMAC\n",__FUNCTION__);
! 	/*must take account of CH 0*/
  
! 	for (i=fd->ch_min; i<=fd->ch_max; i++) {
! 		struct dma_channel *channel;
! 		channel = get_dma_channel(i);
! 		channel->priv_data = &fd->channel[i];
! 		fd->channel[i].cur_cfg = channel;
! 		fd->channel[i].fd = fd;
  	}
  
! 	err =request_irq(platform_get_irq(pdev, 0),
! 			 fdma_irq,
! 			 IRQF_DISABLED | IRQF_SHARED,
! 			 fd->name,
! 			 fd);
! 	if(err <0)
! 		panic(" Cant Register irq %d for FDMA engine err %d\n",
! 					fd->irq_val,err);
! 
  
! 	fdma_register_caps(fd);
  
! 	fdma_check_firmware_state(fd);
  
! 	platform_set_drvdata(pdev, fd);
  
  	return 0;
  }
  
  static int fdma_driver_remove(struct platform_device *pdev)
  {
! 	struct fdma_dev *fd = platform_get_drvdata(pdev);
  
! 	fdma_disable_all_channels(fd);
! 	iounmap(fd->io_base);
! 	dma_pool_destroy(fd->llu_pool);
! 	free_irq(fd->irq_val, fd);
! 	unregister_dmac(&fd->dma_info);
! 	release_resource(fd->phys_mem);
! 	kfree(fd);
  
  	return 0;
  }
  
  static struct platform_driver fdma_driver = {
! 	.driver = {
! 		.name = "stmfdma",
! 	},
  	.probe = fdma_driver_probe,
  	.remove = fdma_driver_remove,
  };
*** linux-sh4-2.6.23.17_stm23_0119-orig/drivers/stm/fdma.h	2009-06-06 20:17:15.000000000 +0200
--- linux-sh4-2.6.23.17_stm23_0119/drivers/stm/fdma.h	2009-06-10 21:39:09.000000000 +0200
***************
*** 7,20 ****
   * License.  See linux/COPYING for more information.
   */
  
! #ifndef __STM_FDMA_H
! #define __STM_FDMA_H
  
  #define CHAN_ALL_ENABLE 				3
  
  /**cmd stat vals*/
! #define SET_NODE_COMP_PAUSE		    		(1 << 30)
! #define SET_NODE_COMP_IRQ				(1 << 31)
  #define NODE_ADDR_STATIC 				0x01
  #define NODE_ADDR_INCR	 				0x02
  
--- 7,20 ----
   * License.  See linux/COPYING for more information.
   */
  
! #ifndef STB7100_FDMA_H
! #define STB7100_FDMA_H
  
  #define CHAN_ALL_ENABLE 				3
  
  /**cmd stat vals*/
! #define SET_NODE_COMP_PAUSE		    		1 <<30
! #define SET_NODE_COMP_IRQ				1 <<31
  #define NODE_ADDR_STATIC 				0x01
  #define NODE_ADDR_INCR	 				0x02
  
***************
*** 25,33 ****
  #define CMDSTAT_FDMA_START_CHANNEL			1
  #define CMDSTAT_FDMA_RESTART_CHANNEL			0
  
! #define FDMA_CHANS					16
! #define FDMA_7100_REQ_LINES				32
! #define FDMA_7200_REQ_LINES				64
  
  /*******************************/
  /*MBOX SETUP VALUES*/
--- 25,35 ----
  #define CMDSTAT_FDMA_START_CHANNEL			1
  #define CMDSTAT_FDMA_RESTART_CHANNEL			0
  
! #define STB7100_FDMA_CHANS              		16
! #define STB7109_FDMA_CHANS              		STB7100_FDMA_CHANS
! #define STB7200_FDMA_CHANS				32
! #define STB7100_REQ_LINES				32
! #define STB7200_REQ_LINES				64
  
  /*******************************/
  /*MBOX SETUP VALUES*/
***************
*** 37,45 ****
  #define MBOX_CMD_START_CHANNEL       			1
  #define CLEAR_WORD					0XFFFFFFFF
  
! #define CMD_STAT_REG(_chan_num) \
! 		(fdma->io_base + fdma->regs.fdma_cmd_statn + \
! 		(_chan_num * CMD_STAT_OFFSET))
  
  #define FDMA_CHANNEL_IDLE 		0
  #define FDMA_CHANNEL_RUNNING 		2
--- 39,65 ----
  #define MBOX_CMD_START_CHANNEL       			1
  #define CLEAR_WORD					0XFFFFFFFF
  
! #define IS_PACED_CHANNEL_SET(flags)(flags & 0x1f)
! #define ASSERT_NODE_BUS_ADDR(addr)( (((PXSEG(addr) == P0SEG) && addr))?1:0)
! #define IS_CHANNEL_PAUSED(fd,ch)(stb710x_get_engine_status(fd,ch)== FDMA_CHANNEL_PAUSED ?1:0)
! #define IS_CHANNEL_RUNNING(fd,ch)(stb710x_get_engine_status(fd,ch)== FDMA_CHANNEL_RUNNING ?1:0)
! #define IS_CHANNEL_IDLE(fd,ch)(stb710x_get_engine_status(fd,ch)== FDMA_CHANNEL_IDLE ?1:0)
! #define IS_TRANSFER_SG(parms)((MODE_SRC_SCATTER==parms->mode)||(MODE_DST_SCATTER==parms->mode )?1:0)
! #define MBOX_STR_CMD(ch) (MBOX_CMD_START_CHANNEL << (ch*2))
! #define CMD_STAT_REG(ch)(fd->io_base + fd->regs.fdma_cmd_statn + (ch * CMD_STAT_OFFSET))
! 
! #define IS_NODE_MALLOCED(priv)((priv.node!=0))
! 
! 
! #define IS_NODELIST_EQUAL(priv)((priv.sublist_nents == priv.alloced_nents))
! #define FDMA_CHAN(channel) ((struct channel_status*)(channel->priv_data))
! #define FDMA_DEV(channel) (FDMA_CHAN(channel)->fd)
! struct fdma_dev;
! 
! typedef void (*pf)(void * data);
! 
! #define CHANNEL_ERR_IRQ 		3
! #define CHANNEL_IRQ     		1
  
  #define FDMA_CHANNEL_IDLE 		0
  #define FDMA_CHANNEL_RUNNING 		2
***************
*** 51,57 ****
  
  #define CHAN_NUM(chan) ((chan) - chip.channel)
  
! struct fdma_llu_entry {
  	u32 next_item;
  	u32 control;
  	u32 size_bytes;
--- 71,77 ----
  
  #define CHAN_NUM(chan) ((chan) - chip.channel)
  
! typedef struct fdma_llu_entry {
  	u32 next_item;
  	u32 control;
  	u32 size_bytes;
***************
*** 60,85 ****
  	u32 line_len;
  	u32 sstride;
  	u32 dstride;
! };
  
  
! struct fdma_llu_node {
! 	struct fdma_llu_entry *virt_addr;
  	dma_addr_t dma_addr;
  };
  
  
! struct fdma_xfer_descriptor {
! 	struct fdma_llu_node *(*extrapolate_fn)(struct stm_dma_params *xfer,
! 			struct fdma_xfer_descriptor *desc,
! 			struct fdma_llu_node *nodes);
! 	int extrapolate_line_len;
  	struct fdma_llu_entry template_llu;
  
  	/* only used when this is the first parameter in a list */
! 	struct fdma_llu_node *llu_nodes;
! 	int alloced_nodes;
! };
  
  
  enum fdma_state {
--- 80,105 ----
  	u32 line_len;
  	u32 sstride;
  	u32 dstride;
! }fdma_llu_entry;
  
  
! struct llu_node{
! 	struct fdma_llu_entry * virt_addr;
  	dma_addr_t dma_addr;
  };
  
  
! typedef struct dma_xfer_descriptor {
! 	struct llu_node* (*extrapolate_fn)(struct stm_dma_params *xfer,
! 					   struct dma_xfer_descriptor *desc,
! 					   struct llu_node* nodes);
! 	int	extrapolate_line_len;
  	struct fdma_llu_entry template_llu;
  
  	/* only used when this is the first parameter in a list */
! 	struct 	llu_node *llu_nodes;
! 	int 	alloced_nodes;
! }dma_xfer_descriptor;
  
  
  enum fdma_state {
***************
*** 91,103 ****
  	FDMA_PAUSED,
  };
  
! struct fdma;
! 
! struct fdma_channel {
! 	struct fdma *fdma;
! 	int chan_num;
  	enum fdma_state sw_state;
! 	struct dma_channel *dma_chan;
  	struct stm_dma_params *params;
  	struct tasklet_struct fdma_complete;
  	struct tasklet_struct fdma_error;
--- 111,120 ----
  	FDMA_PAUSED,
  };
  
! struct channel_status {
! 	struct fdma_dev *fd;
  	enum fdma_state sw_state;
! 	struct dma_channel * cur_cfg;
  	struct stm_dma_params *params;
  	struct tasklet_struct fdma_complete;
  	struct tasklet_struct fdma_error;
***************
*** 105,134 ****
  
  #define FDMA_NAME_LEN 20
  
! struct fdma {
! 	char name[FDMA_NAME_LEN];
! 	struct dma_info dma_info;
! 	struct fdma_channel channels[FDMA_CHANS];
! 	spinlock_t channels_lock; /* protects channels array */
! 	struct resource *phys_mem;
! 	void __iomem *io_base;
! 	u32 firmware_loaded;
! 	u8 ch_min;
! 	u8 ch_max;
! 	u8 irq;
! 	u8 fdma_num;
! 	u32 ch_status_mask;
! 	struct dma_pool *llu_pool;
! 	wait_queue_head_t fw_load_q;
! 
! 	struct fdma_regs regs;
! 
! 	char *fw_name;
! 	struct fdma_fw fw;
! 	int comp_ch;
  
  	/* This is used with the xbar to allocate the next available req line */
! 	unsigned long req_lines_inuse;
  };
  
  typedef volatile unsigned long device_t;
--- 122,151 ----
  
  #define FDMA_NAME_LEN 20
  
! struct fdma_dev {
! 	char				name[FDMA_NAME_LEN];
! 	struct dma_info 		dma_info;
! 	struct channel_status		channel[STB7100_FDMA_CHANS];
! 	spinlock_t 			channel_lock;
! 	struct resource *		phys_mem;
! 	void __iomem			*io_base;
! 	u32				firmware_loaded;
! 	u8				ch_min;
! 	u8 				ch_max;
! 	u8				irq_val;
! 	u8				fdma_num;
! 	u32				ch_status_mask;
! 	struct dma_pool 		*llu_pool;
! 	wait_queue_head_t		fw_load_q;
! 
! 	struct fdma_regs		regs;
! 
! 	char *				fw_name;
! 	struct fdma_fw			fw;
! 	int				comp_ch;
  
  	/* This is used with the xbar to allocate the next available req line */
! 	unsigned long 			req_lines_inuse;
  };
  
  typedef volatile unsigned long device_t;
***************
*** 146,152 ****
  #endif
  
  struct stm_dma_req {
! 	struct fdma_channel *channel;
  	int local_req_line;
  };
  
--- 163,169 ----
  #endif
  
  struct stm_dma_req {
! 	struct channel_status *chan;
  	int local_req_line;
  };
  
